{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Recommandation Part: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function definition and realize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function that load the json file and store it in an array\n",
    "def loadFile(filename):\n",
    "    datas = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            datas.append(json.loads(line))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the files and store the book id including in idSet, this fuction won't be used in the project\n",
    "def loadFileDict(filename, idSet):\n",
    "    datax = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            new = json.loads(line)\n",
    "            if new['book_id'] in idSet:\n",
    "                datax.append(json.loads(line))\n",
    "        f.close()\n",
    "    result = {}\n",
    "    for meta in datax:\n",
    "        user = meta['user_id']\n",
    "        if user not in result:\n",
    "            if len(result) >= 70000:\n",
    "                break;\n",
    "            else:\n",
    "                result[user] = {}\n",
    "                result[user]['book_id'] = []\n",
    "                result[user]['rate'] = []\n",
    "                result[user]['isRead'] = []\n",
    "            result[user]['book_id'].append(meta['book_id'])\n",
    "            result[user]['rate'].append(meta['rating'])\n",
    "            result[user]['isRead'].append(meta['isRead'])\n",
    "    pprint(filename)\n",
    "    pprint(len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate the data, store the rated data in the first dict, the read but un-rated data in the second dict\n",
    "#the un-read data in the third dict\n",
    "def sep_data(datas):\n",
    "    result = [];\n",
    "    ReadYes = {}\n",
    "    ReadNo = {}\n",
    "    ReadUnknown = {}\n",
    "    for user in datas:\n",
    "        meta = datas[user];\n",
    "        for i in range(len(meta['isRead'])):\n",
    "            if meta['isRead'][i] == True: \n",
    "                if meta['rate'][i] == 0:\n",
    "                    if user not in ReadUnknown:\n",
    "                        ReadUnknown[user] = {}\n",
    "                        ReadUnknown[user]['book_id'] = []\n",
    "                        ReadUnknown[user]['rate'] = []\n",
    "                    ReadUnknown[user]['book_id'].append(meta['book_id'][i])\n",
    "                    ReadUnknown[user]['rate'].append(0)                \n",
    "                else:\n",
    "                    if user not in ReadYes:\n",
    "                        ReadYes[user] = {}\n",
    "                        ReadYes[user]['book_id'] = []\n",
    "                        ReadYes[user]['rate'] = []\n",
    "                    ReadYes[user]['book_id'].append(meta['book_id'][i])\n",
    "                    ReadYes[user]['rate'].append(meta['rate'][i])\n",
    "            else:\n",
    "                if user not in ReadNo:\n",
    "                    ReadNo[user] = {}\n",
    "                    ReadNo[user]['book_id'] = []\n",
    "                    ReadNo[user]['rate'] = []\n",
    "                ReadNo[user]['book_id'].append(meta['book_id'][i])\n",
    "                ReadNo[user]['rate'].append(5) \n",
    "    result.append(ReadYes)\n",
    "    result.append(ReadNo)\n",
    "    result.append(ReadUnknown)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to convert the originally read metaData into a dictionary with user id as the search.\n",
    "def transToDict(dataUserMeta):\n",
    "    dict_user = {}\n",
    "    for meta in dataUserMeta:\n",
    "        if meta['isRead'] != True:\n",
    "            continue;\n",
    "        user_id = meta['user_id'];\n",
    "        book_id = meta['book_id'];\n",
    "        if user_id not in dict_user:\n",
    "            dict_user[user_id] = {};\n",
    "            dict_user[user_id]['book_id'] = [];\n",
    "            dict_user[user_id]['rate'] = [];\n",
    "            dict_user[user_id]['isRead'] = [];\n",
    "        dict_user[user_id]['book_id'].append(book_id);\n",
    "        dict_user[user_id]['rate'].append(meta['rating']);\n",
    "        dict_user[user_id]['isRead'].append(meta['isRead']);\n",
    "    return dict_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer the un-read data with a rating 5\n",
    "def transFindRemain(dataUserMeta):\n",
    "    dict_remain = {}\n",
    "    for meta in dataUserMeta:\n",
    "        if meta['isRead'] == True:\n",
    "            continue;\n",
    "        user_id = meta['user_id'];\n",
    "        book_id = meta['book_id'];\n",
    "        if user_id not in dict_user:\n",
    "            dict_user[user_id] = {};\n",
    "            dict_user[user_id]['book_id'] = [];\n",
    "            dict_user[user_id]['rate'] = [];\n",
    "        dict_user[user_id]['book_id'].append(book_id);\n",
    "        dict_user[user_id]['rate'].append(5);\n",
    "    return dict_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer the dict-array data structure to dict-dict\n",
    "def trans_array_to_dict(dicto):\n",
    "    result = {}\n",
    "    for username in dicto:\n",
    "        result[username] = {}\n",
    "        for i in range(len(dicto[username]['book_id'])):\n",
    "            result[username][dicto[username]['book_id'][i]] = dicto[username]['rate'][i]\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the user-index dict from the data\n",
    "def buildUserIndex(datas):\n",
    "    result = {}\n",
    "    count = 0\n",
    "    for user in datas:\n",
    "        result[user] = count;\n",
    "        count +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the book-index dict from the data\n",
    "def buildBookIndex(inputValue):\n",
    "    result = {}\n",
    "    count = 0\n",
    "    for user in inputValue:\n",
    "        for book in inputValue[user]['book_id']:\n",
    "            if book not in result:\n",
    "                result[book] = count;\n",
    "                count += 1;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the data from different dict\n",
    "def mergedata(target, origin):\n",
    "    for user in origin:\n",
    "        if user not in target:\n",
    "            target[user] = {}\n",
    "            target[user]['book_id'] = []\n",
    "            target[user]['rate'] = []\n",
    "            target[user]['isRead'] = []\n",
    "        target[user]['book_id'].extend(origin[user]['book_id'])\n",
    "        target[user]['rate'].extend(origin[user]['rate'])\n",
    "        target[user]['isRead'].extend(origin[user]['isRead'])\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average ratings for every user\n",
    "def cal_avg(d):\n",
    "    result = {}\n",
    "    for user in d:\n",
    "        count = 0;\n",
    "        sums = 0;\n",
    "        for key in d[user]:\n",
    "            sums += d[user][key];\n",
    "            count += 1;\n",
    "        if count == 0:\n",
    "            result[user] = -1;\n",
    "            continue;\n",
    "        result[user] = sums / count;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by original Pearson Correlation\n",
    "def get_single_sim(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    for book in train_dict[user1].keys()&train_dict[user2].keys():\n",
    "        top += ((train_dict[user1][book] - avg1)*(train_dict[user2][book] - avg2))\n",
    "        add1 += pow(train_dict[user1][book] - avg1, 2)\n",
    "        add2 += pow(train_dict[user2][book] - avg2, 2)\n",
    "    if(add1*add2) == 0:\n",
    "        return 0; \n",
    "    result = top / np.sqrt(add1 * add2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by original Pearson Correlation with the weight of the number of rating same books\n",
    "def get_single_sim_ps_improve(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    count = 0;\n",
    "    for book in train_dict[user1].keys()&train_dict[user2].keys():\n",
    "        top += ((train_dict[user1][book] - avg1)*(train_dict[user2][book] - avg2))\n",
    "        add1 += pow(train_dict[user1][book] - avg1, 2)\n",
    "        add2 += pow(train_dict[user2][book] - avg2, 2)\n",
    "        count += 1;\n",
    "    if(add1*add2) == 0:\n",
    "        return 0; \n",
    "    weight = count / 5;\n",
    "#    if count > 2:\n",
    "#        pprint(count)\n",
    "    if weight > 1:\n",
    "        weight = 1;\n",
    "    result = top / np.sqrt(add1 * add2) * weight \n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by cosine similarity\n",
    "def get_single_sim_cos(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    count = 0;\n",
    "    flag1 = 0;\n",
    "    flag2 = 0;\n",
    "    for book in train_dict[user1].keys()|train_dict[user2].keys():\n",
    "        if book in train_dict[user1].keys():\n",
    "            eval1 = train_dict[user1][book]\n",
    "            flag1 = 1;\n",
    "        else:\n",
    "            eval1 = 0;\n",
    "            flag1 = 0;\n",
    "\n",
    "        if book in train_dict[user2].keys():\n",
    "            eval2 = train_dict[user2][book]\n",
    "            flag2 = 1;\n",
    "        else:\n",
    "            eval2 = 0;\n",
    "            flag2 = 0;\n",
    "        top += (eval1 * eval2)\n",
    "        add1 += pow(eval1, 2)\n",
    "        add2 += pow(eval2, 2)\n",
    "        count += (flag1 * flag2);\n",
    "    if(add1*add2) == 0:\n",
    "        return 0; \n",
    "#    if count > 3:\n",
    "#        count = 3;\n",
    "    result = top / np.sqrt(add1 * add2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by Pearson Correlation\n",
    "\n",
    "def pred_test(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) \n",
    "    count = 0;\n",
    "    for username in test_:\n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username]; \n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]: \n",
    "                        r += k * get_single_sim(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by improved Pearson Correlation\n",
    "def pred_test_im(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) \n",
    "    count = 0;\n",
    "    for username in test_: \n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username]; \n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]: \n",
    "                        r += k * get_single_sim_ps_improve(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by Cosine\n",
    "def pred_test_cos(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) \n",
    "    count = 0;\n",
    "    for username in test_: \n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username]; \n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]: \n",
    "                        r += k * get_single_sim_cos(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the book set \n",
    "def gen_bookset(train_):\n",
    "    result = {}\n",
    "    for username in train_:\n",
    "        for book in train_[username]:\n",
    "            if book not in result:\n",
    "                result[book] = set()\n",
    "            result[book].add(username)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MAE for dict data.\n",
    "def cal_mae(test, pred):\n",
    "    count = 0;\n",
    "    sum_mae = 0;\n",
    "    for user in pred:\n",
    "        for book in pred[user]:\n",
    "            sum_mae += np.abs(pred[user][book] - test[user][book]);\n",
    "            count += 1;\n",
    "    return sum_mae / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RMSE for dict data.\n",
    "def cal_rmse(test, pred):\n",
    "    count = 0;\n",
    "    sum_rmse = 0;\n",
    "    for user in pred:\n",
    "        for book in pred[user]:\n",
    "            sum_rmse += ((pred[user][book] - test[user][book])** 2);\n",
    "            count += 1;\n",
    "    return math.sqrt(sum_rmse / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using factorized matrixes to predict\n",
    "def prediction(P, Q):\n",
    "    result = np.dot(P.T, Q)\n",
    "#    if result > 5:\n",
    "#        result = 5\n",
    "#    else:\n",
    "#        if result < 0:\n",
    "#            result = 0;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict ratings for the books rated in the test set by MF\n",
    "def predictions(P, Q, T):\n",
    "    user, book = T.nonzero()\n",
    "    Z = np.zeros((len(P.T), len(Q[0])))   \n",
    "    for u, i in zip(user, book):\n",
    "        pred = prediction(P[:,u], Q[:, i])\n",
    "        if pred > 5:\n",
    "            pred = 5;\n",
    "        else:\n",
    "            if pred < 1:\n",
    "                pred = 1;\n",
    "        Z[u, i] = pred\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the book/user-index dict to index-book/user dict.\n",
    "def convert_dict(dicts):\n",
    "    result = {}\n",
    "    for user in dicts:\n",
    "        result[dicts[user]] = user\n",
    "    return result;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RMSE for matrix data.\n",
    "def rmse(I, R, M):\n",
    "    count = np.sum(I);\n",
    "    return np.sqrt(np.sum((I * (R - M)) ** 2) / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MAE for matrix data.\n",
    "def mae(I, R, M):\n",
    "    count = np.sum(I);\n",
    "    return np.sum(np.abs(I * (R - M))) / count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36514\n"
     ]
    }
   ],
   "source": [
    "#Load the book_id to title data\n",
    "poetry_dict = loadFile('poemTitle.json')[0]\n",
    "pprint(len(poetry_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from json file\n",
    "dataMetaAll = loadFile('goodreads_interactions_poetry.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trransfer the data to the dict that indexed by user_id\n",
    "dataDict = transToDict(dataMetaAll)\n",
    "dict_all = dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282415\n",
      "36374\n"
     ]
    }
   ],
   "source": [
    "#Build the user-index dict and book-index dict\n",
    "user_index = buildUserIndex(dict_all)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_all);\n",
    "pprint(len(book_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Presonalize books for 2 actual users using Pearson method\n",
    "In the code of this part, it only shows the process of find two users rating data, and recommand for the user 2, We can also use this code to predict the result by changing the part of \"Build the train set and test set for the user 2\". The target_user can be changed to the user_id of user 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fab3e0cea61720dc85881bfc09d06b97'\n",
      "{'book_id': ['34023590', '25330489', '18003300'],\n",
      " 'isRead': [True, True, True],\n",
      " 'rate': [2, 4, 3]}\n"
     ]
    }
   ],
   "source": [
    "#Find the User that rate less book (User2)\n",
    "user_min = 0;\n",
    "count = 0\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['book_id']) == 3:\n",
    "        count += 1\n",
    "        user_min = user\n",
    "        if count > 20:\n",
    "            break;\n",
    "pprint(user_min)\n",
    "pprint(dict_all[user_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sad Girls'\n",
      "'Memories'\n",
      "'Love & Misadventure'\n"
     ]
    }
   ],
   "source": [
    "#Print the books he reated\n",
    "for book in dict_all[user_min]['book_id']:\n",
    "    pprint(poetry_dict[book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rate': {'18003300': 3, '25330489': 4, '34023590': 2},\n",
      " 'user_id': 'fab3e0cea61720dc85881bfc09d06b97'}\n"
     ]
    }
   ],
   "source": [
    "#Print the information that will store, it user_id is 'fab3e0cea61720dc85881bfc09d06b97'\n",
    "dict_less = {}\n",
    "dict_less['user_id'] = user_min\n",
    "dict_less['rate'] = {}\n",
    "for i in range(len(dict_all[user_min]['book_id'])):\n",
    "    dict_less['rate'][dict_all[user_min]['book_id'][i]] = dict_all[user_min]['rate'][i]\n",
    "pprint(dict_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rate': {'12914': 4,\n",
      "          '1371': 5,\n",
      "          '1381': 5,\n",
      "          '1519': 4,\n",
      "          '1715': 4,\n",
      "          '2696': 4,\n",
      "          '764332': 4},\n",
      " 'user_id': '26b5bed05bcabbabdaec4ee08fc43244'}\n"
     ]
    }
   ],
   "source": [
    "#Find the User's id is '26b5bed05bcabbabdaec4ee08fc43244'\n",
    "dict_more = {}\n",
    "dict_more['user_id'] = '26b5bed05bcabbabdaec4ee08fc43244'\n",
    "user_more = '26b5bed05bcabbabdaec4ee08fc43244'\n",
    "dict_more['rate'] = {}\n",
    "for i in range(len(dict_all[user_more]['book_id'])):\n",
    "    dict_more['rate'][dict_all[user_more]['book_id'][i]] = dict_all[user_more]['rate'][i]\n",
    "pprint(dict_more)\n",
    "for book in dict_all[user_more]['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'764332'\n",
      "'Jason and the Golden Fleece'\n",
      "'1519'\n",
      "'The Oresteia  (Ορέστεια, #1-3)'\n",
      "'1715'\n",
      "'Metamorphoses'\n",
      "'12914'\n",
      "'The Aeneid'\n",
      "'1371'\n",
      "'The Iliad'\n",
      "'1381'\n",
      "'The Odyssey'\n",
      "'2696'\n",
      "'The Canterbury Tales'\n",
      "'764332'\n",
      "'Jason and the Golden Fleece'\n",
      "'1519'\n",
      "'The Oresteia  (Ορέστεια, #1-3)'\n",
      "'1715'\n",
      "'Metamorphoses'\n",
      "'12914'\n",
      "'The Aeneid'\n",
      "'1371'\n",
      "'The Iliad'\n"
     ]
    }
   ],
   "source": [
    "#Print the rate records, the duplicate records will be merge\n",
    "for book in dict_all[user_more]['book_id']:\n",
    "    pprint(book)\n",
    "    pprint(poetry_dict[book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rate': {'18003300': 3, '25330489': 4, '34023590': 2},\n",
      "  'user_id': 'fab3e0cea61720dc85881bfc09d06b97'},\n",
      " {'rate': {'12914': 4,\n",
      "           '1371': 5,\n",
      "           '1381': 5,\n",
      "           '1519': 4,\n",
      "           '1715': 4,\n",
      "           '2696': 4,\n",
      "           '764332': 4},\n",
      "  'user_id': '26b5bed05bcabbabdaec4ee08fc43244'}]\n"
     ]
    }
   ],
   "source": [
    "#Build the data structure that store the rate informating of that two users\n",
    "restore = []\n",
    "restore.append(dict_less)\n",
    "restore.append(dict_more)\n",
    "pprint(restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the users information\n",
    "with open('two_user_end.json', 'wt') as file_obj:\n",
    "    json.dump(restore, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the train set of user 2\n",
    "dict_re = {};\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['isRead']) >= 10 or user == user_min:\n",
    "        dict_re[user] = dict_all[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n",
      "33926\n",
      "27873\n"
     ]
    }
   ],
   "source": [
    "#Build the train set and test set for the user 2\n",
    "array_2 = []\n",
    "array_2 = sep_data(dict_re)\n",
    "dict_user = array_2[0]\n",
    "dict_remain = array_2[1]\n",
    "dict_unknown = array_2[2]\n",
    "\n",
    "target_user = 'fab3e0cea61720dc85881bfc09d06b97'\n",
    "\n",
    "user_index = buildUserIndex(dict_re)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_re);\n",
    "pprint(len(book_index))\n",
    "\n",
    "train_dict = dict_user\n",
    "test_dict = {}\n",
    "test_dict[target_user] = {}\n",
    "test_dict[target_user]['book_id'] = []\n",
    "test_dict[target_user]['rate'] = []\n",
    "\n",
    "for book in book_index:\n",
    "    if book not in dict_all[target_user]['book_id']:\n",
    "        test_dict[target_user]['book_id'].append(book)\n",
    "        test_dict[target_user]['rate'].append(1)\n",
    "\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "\n",
    "pprint(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27873\n"
     ]
    }
   ],
   "source": [
    "pprint(len(dict_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_id': ['34023590', '25330489', '18003300'], 'rate': [2, 4, 3]}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict_user[target_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the data of rated books\n",
    "with open('source_dict.json', 'wt') as file_obj:\n",
    "    json.dump(dict_user, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n",
      "36374\n"
     ]
    }
   ],
   "source": [
    "#Build the user-index dict and book-index dict\n",
    "user_index = buildUserIndex(dict_re)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_all);\n",
    "pprint(len(book_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246699\n"
     ]
    }
   ],
   "source": [
    "#Transfer the train set and test set from dict-array to dict-dict\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "#userset = get_set([],train_dict);\n",
    "print(len(train_))\n",
    "#print(train_['8842281e1d1347389f2ab93d60773d4d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the data\n",
    "res = pred_test_im(train_, test_, 1000000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33923\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    result = res[i]\n",
    "pprint(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the predict result\n",
    "sorted_x=sorted(result.items(), key = operator.itemgetter(1))\n",
    "start = len(sorted_x) - 51;\n",
    "end = len(sorted_x) - 1;\n",
    "#pprint(sorted_x[end][0])\n",
    "result_id = []\n",
    "for i in range(end, start, -1):\n",
    "    result_id.append(sorted_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22151696',\n",
      " '29431081',\n",
      " '23513349',\n",
      " '25384844',\n",
      " '23434371',\n",
      " '13123245',\n",
      " '13105527',\n",
      " '35606560',\n",
      " '25746714',\n",
      " '19230408',\n",
      " '23534',\n",
      " '18288210',\n",
      " '29457318',\n",
      " '13376363',\n",
      " '32468495',\n",
      " '7824768',\n",
      " '6017893',\n",
      " '980426',\n",
      " '20821097',\n",
      " '11625',\n",
      " '23522212',\n",
      " '29758714',\n",
      " '31443393',\n",
      " '6944946',\n",
      " '25986828',\n",
      " '1294049',\n",
      " '24688932',\n",
      " '25334576',\n",
      " '19265831',\n",
      " '26850255',\n",
      " '27494',\n",
      " '47713',\n",
      " '400412',\n",
      " '3049',\n",
      " '3109162',\n",
      " '5868421',\n",
      " '539143',\n",
      " '34296927',\n",
      " '1434',\n",
      " '1371',\n",
      " '33667125',\n",
      " '42051',\n",
      " '5865732',\n",
      " '11958571',\n",
      " '12122965',\n",
      " '8098264',\n",
      " '26702564',\n",
      " '29752702',\n",
      " '29335538',\n",
      " '24717410']\n",
      "['34023590', '25330489', '18003300']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#Print the book id result of user 2\n",
    "book_list = []\n",
    "for i in range(50):\n",
    "    book_list.append(result_id[i][0])\n",
    "pprint(book_list)\n",
    "book_rate = []\n",
    "for book_id in train_[target_user]:\n",
    "    book_rate.append(book_id)\n",
    "pprint(book_rate)\n",
    "print(len(book_list))\n",
    "#book_list.extend(book_rate)\n",
    "#pprint(book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('22151696', 'Lullabies'),\n",
      " ('29431081', 'The Universe of Us'),\n",
      " ('23513349', 'Milk and Honey'),\n",
      " ('25384844', 'Black Butterfly'),\n",
      " ('23434371', 'Beautiful Chaos'),\n",
      " ('13123245', 'B'),\n",
      " ('13105527', 'I Wrote This For You'),\n",
      " ('35606560', 'The Sun and Her Flowers'),\n",
      " ('25746714', 'The Type'),\n",
      " ('19230408', 'I Wrote This For You: Just the Words'),\n",
      " ('23534', 'Love Is a Dog from Hell'),\n",
      " ('18288210', 'No Matter the Wreckage'),\n",
      " ('29457318', 'Habang Wala Pa Sila: Mga Tula ng Pag-ibig'),\n",
      " ('13376363', 'Teaching My Mother How to Give Birth'),\n",
      " ('32468495', 'Pillow Thoughts'),\n",
      " ('7824768', 'ليتها تقرأ'),\n",
      " ('6017893', 'قهوة وشيكولاتة'),\n",
      " ('980426', 'Love Poems'),\n",
      " ('20821097', 'Chasers of the Light: Poems from the Typewriter Series'),\n",
      " ('11625', 'Ariel: The Restored Edition'),\n",
      " ('23522212', 'Mouthful of Forevers'),\n",
      " ('29758714', 'Dirty Pretty Things'),\n",
      " ('31443393', 'Note to Self'),\n",
      " ('6944946', 'يوميات امرأة لا مبالية'),\n",
      " ('25986828', 'Today Means Amen'),\n",
      " ('1294049', 'Love Songs'),\n",
      " ('24688932', 'All The Things I Never Said'),\n",
      " ('25334576', 'Grief is the Thing with Feathers'),\n",
      " ('19265831', 'Hello, Baby'),\n",
      " ('26850255', 'To The Women I Once Loved'),\n",
      " ('27494', 'Leaves of Grass'),\n",
      " ('47713', 'Collected Poems, 1912-1944'),\n",
      " ('400412', 'The Waste Land and Other Poems'),\n",
      " ('3049', 'Sir Gawain and the Green Knight'),\n",
      " ('3109162', 'Ballistics'),\n",
      " ('5868421', 'الرسم بالكلمات'),\n",
      " ('539143', \"The World Doesn't End\"),\n",
      " ('34296927', 'I Love My Love'),\n",
      " ('1434', 'Hamlet'),\n",
      " ('1371', 'The Iliad'),\n",
      " ('33667125', 'Lace Bone Beast: Poems & Other Fairytales for Wicked Girls'),\n",
      " ('42051', 'The Complete Sonnets and Poems'),\n",
      " ('5865732', 'سيبقى الحب سيدي'),\n",
      " ('11958571', 'آخر الليل'),\n",
      " ('12122965', 'أوراق الزيتون'),\n",
      " ('8098264', 'الخيانة.. مشوار محرج لحد الحزن'),\n",
      " ('26702564', 'Leave This Song Behind: Teen Poetry at Its Best'),\n",
      " ('29752702', 'Whiskey Words & a Shovel II'),\n",
      " ('29335538', 'Lavender'),\n",
      " ('24717410', 'B')]\n"
     ]
    }
   ],
   "source": [
    "#Print the result with the title\n",
    "res_list = []\n",
    "for i in range(len(book_list)):\n",
    "    ins = (book_list[i], poetry_dict[book_list[i]])\n",
    "    res_list.append(ins)\n",
    "pprint(res_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store user2's information\n",
    "with open('rc_po_5_less.json', 'wt') as file_obj:\n",
    "    json.dump(res_list, file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The predict and evaluation from multiple methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34023590', '25330489', '18003300']\n",
      "[2, 4, 3]\n",
      "27873\n",
      "27873\n"
     ]
    }
   ],
   "source": [
    "#Get the test set and train set for the evaluation part\n",
    "target_book = dict_user[target_user]['book_id']\n",
    "target_rating = dict_user[target_user]['rate']\n",
    "pprint(target_book)\n",
    "pprint(target_rating)\n",
    "if target_user in dict_remain:\n",
    "    pprint(dict_remain[target_user]['book_id'])\n",
    "if target_user in dict_unknown:\n",
    "    pprint(dict_unknown[target_user]['book_id'])\n",
    "\n",
    "test_dict = {}\n",
    "train_dict = {}\n",
    "for userMeta in dict_user:\n",
    "#    if len(dict_user[userMeta]['book_id']) < 10:\n",
    "#        continue;\n",
    "    test_dict[userMeta] = {};\n",
    "    train_dict[userMeta] = {};\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_id,all_rating,test_size=0.33)\n",
    "    test_dict[userMeta]['book_id'] = x_test;\n",
    "    test_dict[userMeta]['rate'] = y_test;\n",
    "    train_dict[userMeta]['book_id'] = x_train;\n",
    "    train_dict[userMeta]['rate'] = y_train;\n",
    "\n",
    "#for userMeta in dict_remain:\n",
    "#    if userMeta not in train_dict:\n",
    "#        train_dict[userMeta] = {}\n",
    "#        train_dict[userMeta]['book_id'] = []\n",
    "#        train_dict[userMeta]['rate'] = []\n",
    "#    train_dict[userMeta]['book_id'].extend(dict_remain[userMeta]['book_id']);\n",
    "#    train_dict[userMeta]['rate'].extend(dict_remain[userMeta]['rate']);\n",
    "\n",
    "#for userMeta in dict_unknown:\n",
    "#    if userMeta not in train_dict:\n",
    "#        train_dict[userMeta] = {}\n",
    "#        train_dict[userMeta]['book_id'] = []\n",
    "#        train_dict[userMeta]['rate'] = []\n",
    "#    train_dict[userMeta]['book_id'].extend(dict_unknown[userMeta]['book_id']);\n",
    "#    train_dict[userMeta]['rate'].extend(dict_unknown[userMeta]['rate']);\n",
    "pprint(len(train_dict))\n",
    "pprint(len(test_dict)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE value is: 0.6927776219125726\n",
      "The RMSE value is: 0.9349987563510308\n"
     ]
    }
   ],
   "source": [
    "#Predict and evaluate for naive Pearson Correlation\n",
    "pred_res = pred_test(train_, test_, 10000);\n",
    "mae = cal_mae(test_, pred_res);\n",
    "rmse = cal_rmse(test_, pred_res);\n",
    "print(\"The MAE value is:\", mae)\n",
    "print(\"The RMSE value is:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6562182740254755\n",
      "0.8625402381412787\n"
     ]
    }
   ],
   "source": [
    "#Predict and evaluate for optimized Pearson Correlation\n",
    "pred_res_im = pred_test_im(train_, test_, 10000);\n",
    "mae_im = cal_mae(test_, pred_res_im);\n",
    "rmse_im = cal_rmse(test_, pred_res_im);\n",
    "print(mae_im)\n",
    "print(rmse_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664604524863647\n",
      "0.8687005229252904\n"
     ]
    }
   ],
   "source": [
    "#Predict and evaluate for cosine similarity\n",
    "pred_res_cos = pred_test_cos(train_, test_, 1000);\n",
    "mae_cos = cal_mae(test_, pred_res_cos);\n",
    "rmse_cos = cal_rmse(test_, pred_res_cos);\n",
    "print(mae_cos)\n",
    "print(rmse_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the train set and test set for evaluation\n",
    "dict_re = {};\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['isRead']) >= 10:\n",
    "        dict_re[user] = dict_all[user]\n",
    "\n",
    "array_2 = []\n",
    "array_2 = sep_data(dict_re)\n",
    "dict_user = array_2[0]\n",
    "dict_remain = array_2[1]\n",
    "dict_unknown = array_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the books that marked as un-read by users\n",
    "dict_remain = {}\n",
    "dict_remain = transFindRemain(dataMetaAll);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rebuild the train set so that we can add the data of dict remain for the matrix factorization\n",
    "#It uses the data that having \n",
    "test_dict = {}\n",
    "train_dict = {}\n",
    "for userMeta in dict_user:\n",
    "#    if len(dict_user[userMeta]['book_id']) < 10:\n",
    "#        continue;\n",
    "    test_dict[userMeta] = {};\n",
    "    train_dict[userMeta] = {};\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_id,all_rating,test_size=0.33)\n",
    "    test_dict[userMeta]['book_id'] = x_test;\n",
    "    test_dict[userMeta]['rate'] = y_test;\n",
    "    train_dict[userMeta]['book_id'] = x_train;\n",
    "    train_dict[userMeta]['rate'] = y_train;\n",
    "\n",
    "\n",
    "for userMeta in dict_remain:\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    if userMeta not in train_dict:\n",
    "        train_dict[userMeta] = {}\n",
    "        train_dict[userMeta]['book_id'] = []\n",
    "        train_dict[userMeta]['rate'] = []\n",
    "    train_dict[userMeta]['book_id'].extend(dict_remain[userMeta]['book_id']);\n",
    "    train_dict[userMeta]['rate'].extend(dict_remain[userMeta]['rate']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index = buildUserIndex(dict_user)\n",
    "book_index = buildBookIndex(dict_user);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the user-index and book-index dict\n",
    "conv_user = convert_dict(user_index)\n",
    "conv_book = convert_dict(book_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameter and the Train and Test matrix\n",
    "lmbda = 0.01 #Regularisation weight\n",
    "k = 20\n",
    "#m = len(user_index) #The length of user matrix\n",
    "m = 10000\n",
    "#m = len(user_index)\n",
    "n = len(book_index) \n",
    "n_epochs = 50\n",
    "gamma = 0.001 #learning rate\n",
    "P = 1 * np.random.rand(k, m)\n",
    "Q = 1 * np.random.rand(k, n)\n",
    "\n",
    "#len_user = 10000\n",
    "#R = np.zeros((len(user_index), len(book_index)));\n",
    "#I = np.zeros((len(user_index), len(book_index)));\n",
    "R = np.zeros((m, len(book_index)));\n",
    "I = np.zeros((m, len(book_index)));\n",
    "count = 0;\n",
    "for user_in in range(m):\n",
    "    user = conv_user[user_in] \n",
    "    if user not in train_:\n",
    "        continue;\n",
    "    for book in train_[user]:\n",
    "        R[user_index[user]][book_index[book]] = train_[user][book]\n",
    "        I[user_index[user]][book_index[book]] = 1\n",
    "    count += 1;\n",
    "\n",
    "count = 0;\n",
    "#T = np.zeros((len(user_index), len(book_index)));\n",
    "#I2 = np.zeros((len(user_index), len(book_index)));\n",
    "T = np.zeros((m, len(book_index)));\n",
    "I2 = np.zeros((m, len(book_index)));\n",
    "for user_in in range(m):\n",
    "    user = conv_user[user_in]\n",
    "    if user not in test_:\n",
    "        continue;\n",
    "#    pprint(user);\n",
    "    for book in test_[user]:\n",
    "        T[user_index[user]][book_index[book]] = test_[user][book] #test set\n",
    "        I2[user_index[user]][book_index[book]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(P[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "#Iterate calculation\n",
    "k = 20\n",
    "lmbda = 0.02\n",
    "n_epochs = 50\n",
    "gamma = 0.005 #learning rate\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "user, book = R.nonzero()\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch)\n",
    "    for u, i in zip(user, book):\n",
    "        e = R[u, i] - prediction(P[:,u], Q[:, i])\n",
    "        P[:, u] += gamma * (e * Q[:, i] - lmbda * P[:, u])\n",
    "        Q[:, i] += gamma * (e * P[:, u] - lmbda * Q[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0.46562236, 0.67916067, 0.44680695, 0.18390048, 0.64692949,\n",
      "       0.01755266, 0.09910645, 0.52350605, 0.04623374, 0.6169816 ,\n",
      "       0.66349279, 0.61015071, 0.40297021, 0.78651147, 0.72557995,\n",
      "       0.41856451, 0.36838965, 0.45838551, 0.70199411, 0.52532535])\n"
     ]
    }
   ],
   "source": [
    "#Print one matrix\n",
    "pprint(P[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'done'\n"
     ]
    }
   ],
   "source": [
    "#Calculate the result\n",
    "PredM = predictions(P, Q, T)\n",
    "pprint(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE by Matrix Factorization with Stochastic Gradient Descent is : 0.3586821446934908\n",
      "RMSE by Matrix Factorization with Stochastic Gradient Descent is : 0.5105274090698148\n"
     ]
    }
   ],
   "source": [
    "#Tr = T[0:10000, :]\n",
    "MAE = mae(I2, T, PredM)\n",
    "RMSE = rmse(I2, T, PredM)\n",
    "print(\"MAE by Matrix Factorization with Stochastic Gradient Descent is :\", MAE)\n",
    "print(\"RMSE by Matrix Factorization with Stochastic Gradient Descent is :\", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
