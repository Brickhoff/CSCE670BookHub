{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Recommandation Part: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function definition and realize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function that load the json file and store it in an array\n",
    "def loadFile(filename):\n",
    "    datas = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            datas.append(json.loads(line))\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the files and store the book id including in idSet, this fuction won't be used in the project\n",
    "def loadFileDict(filename, idSet):\n",
    "    datax = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            new = json.loads(line)\n",
    "            if new['book_id'] in idSet:\n",
    "                datax.append(json.loads(line))\n",
    "        f.close()\n",
    "    result = {}\n",
    "    for meta in datax:\n",
    "        user = meta['user_id']\n",
    "        if user not in result:\n",
    "            if len(result) >= 70000:\n",
    "                break;\n",
    "            else:\n",
    "                result[user] = {}\n",
    "                result[user]['book_id'] = []\n",
    "                result[user]['rate'] = []\n",
    "                result[user]['isRead'] = []\n",
    "            result[user]['book_id'].append(meta['book_id'])\n",
    "            result[user]['rate'].append(meta['rating'])\n",
    "            result[user]['isRead'].append(meta['isRead'])\n",
    "    pprint(filename)\n",
    "    pprint(len(result))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate the data, store the rated data in the first dict, the read but un-rated data in the second dict\n",
    "#the un-read data in the third dict\n",
    "def sep_data(datas):\n",
    "    result = [];\n",
    "    ReadYes = {}\n",
    "    ReadNo = {}\n",
    "    ReadUnknown = {}\n",
    "    for user in datas:\n",
    "        meta = datas[user];\n",
    "        for i in range(len(meta['isRead'])):\n",
    "            if meta['isRead'][i] == True: #If the book in history is read\n",
    "                if meta['rate'][i] == 0:\n",
    "                    if user not in ReadUnknown:\n",
    "                        ReadUnknown[user] = {}\n",
    "                        ReadUnknown[user]['book_id'] = []\n",
    "                        ReadUnknown[user]['rate'] = []\n",
    "                    ReadUnknown[user]['book_id'].append(meta['book_id'][i])\n",
    "                    ReadUnknown[user]['rate'].append(0)                \n",
    "                else:\n",
    "                    if user not in ReadYes:\n",
    "                        ReadYes[user] = {}\n",
    "                        ReadYes[user]['book_id'] = []\n",
    "                        ReadYes[user]['rate'] = []\n",
    "                    ReadYes[user]['book_id'].append(meta['book_id'][i])\n",
    "                    ReadYes[user]['rate'].append(meta['rate'][i])\n",
    "            else:\n",
    "                if user not in ReadNo:\n",
    "                    ReadNo[user] = {}\n",
    "                    ReadNo[user]['book_id'] = []\n",
    "                    ReadNo[user]['rate'] = []\n",
    "                ReadNo[user]['book_id'].append(meta['book_id'][i])\n",
    "                ReadNo[user]['rate'].append(5) \n",
    "    result.append(ReadYes)\n",
    "    result.append(ReadNo)\n",
    "    result.append(ReadUnknown)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to convert the originally read metaData into a dictionary with user id as the search.\n",
    "def transToDict(dataUserMeta):\n",
    "    dict_user = {}\n",
    "    for meta in dataUserMeta:\n",
    "        if meta['isRead'] != True:\n",
    "            continue;\n",
    "        user_id = meta['user_id'];\n",
    "        book_id = meta['book_id'];\n",
    "        if user_id not in dict_user:\n",
    "            dict_user[user_id] = {};\n",
    "            dict_user[user_id]['book_id'] = [];\n",
    "            dict_user[user_id]['rate'] = [];\n",
    "            dict_user[user_id]['isRead'] = [];\n",
    "        dict_user[user_id]['book_id'].append(book_id);\n",
    "        dict_user[user_id]['rate'].append(meta['rating']);\n",
    "        dict_user[user_id]['isRead'].append(meta['isRead']);\n",
    "    return dict_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer the un-read data with a rating 5\n",
    "def transFindRemain(dataUserMeta):\n",
    "    dict_remain = {}\n",
    "    for meta in dataUserMeta:\n",
    "        if meta['isRead'] == True:\n",
    "            continue;\n",
    "        user_id = meta['user_id'];\n",
    "        book_id = meta['book_id'];\n",
    "        if user_id not in dict_user:\n",
    "            dict_user[user_id] = {};\n",
    "            dict_user[user_id]['book_id'] = [];\n",
    "            dict_user[user_id]['rate'] = [];\n",
    "        dict_user[user_id]['book_id'].append(book_id);\n",
    "        dict_user[user_id]['rate'].append(5);\n",
    "    return dict_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer the dict-array data structure to dict-dict\n",
    "def trans_array_to_dict(dicto):\n",
    "    result = {}\n",
    "    for username in dicto:\n",
    "        result[username] = {}\n",
    "        for i in range(len(dicto[username]['book_id'])):\n",
    "            result[username][dicto[username]['book_id'][i]] = dicto[username]['rate'][i]\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the user-index dict from the data\n",
    "def buildUserIndex(datas):\n",
    "    result = {}\n",
    "    count = 0\n",
    "    for user in datas:\n",
    "        result[user] = count;\n",
    "        count +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the book-index dict from the data\n",
    "def buildBookIndex(inputValue):\n",
    "    result = {}\n",
    "    count = 0\n",
    "    for user in inputValue:\n",
    "        for book in inputValue[user]['book_id']:\n",
    "            if book not in result:\n",
    "                result[book] = count;\n",
    "                count += 1;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the data from different dict\n",
    "def mergedata(target, origin):\n",
    "    for user in origin:\n",
    "        if user not in target:\n",
    "            target[user] = {}\n",
    "            target[user]['book_id'] = []\n",
    "            target[user]['rate'] = []\n",
    "            target[user]['isRead'] = []\n",
    "        target[user]['book_id'].extend(origin[user]['book_id'])\n",
    "        target[user]['rate'].extend(origin[user]['rate'])\n",
    "        target[user]['isRead'].extend(origin[user]['isRead'])\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average ratings for every user\n",
    "def cal_avg(d):\n",
    "    result = {}\n",
    "    for user in d:\n",
    "        count = 0;\n",
    "        sums = 0;\n",
    "        for key in d[user]:\n",
    "            sums += d[user][key];\n",
    "            count += 1;\n",
    "        if count == 0:\n",
    "            result[user] = -1;\n",
    "            continue;\n",
    "        result[user] = sums / count;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by original Pearson Correlation\n",
    "def get_single_sim(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    for book in train_dict[user1].keys()&train_dict[user2].keys():\n",
    "        top += ((train_dict[user1][book] - avg1)*(train_dict[user2][book] - avg2))\n",
    "        add1 += pow(train_dict[user1][book] - avg1, 2)\n",
    "        add2 += pow(train_dict[user2][book] - avg2, 2)\n",
    "    if(add1*add2) == 0:\n",
    "        return 0;\n",
    "    result = top / np.sqrt(add1 * add2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by original Pearson Correlation with the weight of the number of rating same books\n",
    "def get_single_sim_ps_improve(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    count = 0;\n",
    "    for book in train_dict[user1].keys()&train_dict[user2].keys():\n",
    "        top += ((train_dict[user1][book] - avg1)*(train_dict[user2][book] - avg2))\n",
    "        add1 += pow(train_dict[user1][book] - avg1, 2)\n",
    "        add2 += pow(train_dict[user2][book] - avg2, 2)\n",
    "        count += 1;\n",
    "    if(add1*add2) == 0:\n",
    "        return 0; #\n",
    "    weight = count / 5;\n",
    "#    if count > 2:\n",
    "#        pprint(count)\n",
    "    if weight > 1:\n",
    "        weight = 1;\n",
    "    result = top / np.sqrt(add1 * add2) * weight #Using weight to scale\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function calculate similarity by cosine similarity\n",
    "def get_single_sim_cos(train_dict, avge_dict, user1, user2):\n",
    "    top = 0;\n",
    "    add1 = 0;\n",
    "    add2 = 0;\n",
    "    avg1 = avge_dict[user1]\n",
    "    avg2 = avge_dict[user2]\n",
    "    count = 0;\n",
    "    flag1 = 0;\n",
    "    flag2 = 0;\n",
    "    for book in train_dict[user1].keys()|train_dict[user2].keys():\n",
    "        if book in train_dict[user1].keys():\n",
    "            eval1 = train_dict[user1][book]\n",
    "            flag1 = 1;\n",
    "        else:\n",
    "            eval1 = 0;\n",
    "            flag1 = 0;\n",
    "\n",
    "        if book in train_dict[user2].keys():\n",
    "            eval2 = train_dict[user2][book]\n",
    "            flag2 = 1;\n",
    "        else:\n",
    "            eval2 = 0;\n",
    "            flag2 = 0;\n",
    "        top += (eval1 * eval2)\n",
    "        add1 += pow(eval1, 2)\n",
    "        add2 += pow(eval2, 2)\n",
    "        count += (flag1 * flag2);\n",
    "    if(add1*add2) == 0:\n",
    "        return 0; \n",
    "#    if count > 3:\n",
    "#        count = 3;\n",
    "    result = top / np.sqrt(add1 * add2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by Pearson Correlation\n",
    "def pred_test(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) #Calculate the average \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) #得到book set\n",
    "    count = 0;\n",
    "    for username in test_: \n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username]; #Add the average at first\n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]: \n",
    "                        r += k * get_single_sim(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by improved Pearson Correlation\n",
    "def pred_test_im(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) \n",
    "    count = 0;\n",
    "    for username in test_: \n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username];\n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]:\n",
    "                        #different\n",
    "                        r += k * get_single_sim_ps_improve(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the ratings by Cosine\n",
    "def pred_test_cos(train_, test_, ranges):\n",
    "    k = 0.02\n",
    "    avg = cal_avg(train_) \n",
    "    result = {}\n",
    "    book_set = gen_bookset(train_) \n",
    "    count = 0;\n",
    "    for username in test_:\n",
    "        result[username] = {}\n",
    "        for book in test_[username]: \n",
    "            r = avg[username]; \n",
    "            if r < 0:\n",
    "                continue;\n",
    "            if book in book_set:\n",
    "                for user_other in book_set[book]: \n",
    "                        r += k * get_single_sim_cos(train_, avg, username, user_other) * (train_[user_other][book] - avg[user_other])\n",
    "            if r > 5:\n",
    "                r = 5;\n",
    "            if r < 1:\n",
    "                r = 1;\n",
    "            result[username][book] = r;\n",
    "        count += 1;\n",
    "        if count >= ranges:\n",
    "            return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the book set \n",
    "def gen_bookset(train_):\n",
    "    result = {}\n",
    "    for username in train_:\n",
    "        for book in train_[username]:\n",
    "            if book not in result:\n",
    "                result[book] = set()\n",
    "            result[book].add(username)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MAE for dict data.\n",
    "def cal_mae(test, pred):\n",
    "    count = 0;\n",
    "    sum_mae = 0;\n",
    "    for user in pred:\n",
    "        for book in pred[user]:\n",
    "            sum_mae += np.abs(pred[user][book] - test[user][book]);\n",
    "            count += 1;\n",
    "    return sum_mae / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RMSE for dict data.\n",
    "def cal_rmse(test, pred):\n",
    "    count = 0;\n",
    "    sum_rmse = 0;\n",
    "    for user in pred:\n",
    "        for book in pred[user]:\n",
    "            sum_rmse += ((pred[user][book] - test[user][book])** 2);\n",
    "            count += 1;\n",
    "    return math.sqrt(sum_rmse / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using factorized matrixes to predict\n",
    "def prediction(P, Q):\n",
    "    result = np.dot(P.T, Q)\n",
    "#    if result > 5:\n",
    "#        result = 5\n",
    "#    else:\n",
    "#        if result < 0:\n",
    "#            result = 0;\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict ratings for the books rated in the test set by MF\n",
    "def predictions(P, Q, T):\n",
    "    user, book = T.nonzero()\n",
    "    Z = np.zeros((len(P.T), len(Q[0])))   \n",
    "    for u, i in zip(user, book):\n",
    "        pred = prediction(P[:,u], Q[:, i])\n",
    "        if pred > 5:\n",
    "            pred = 5;\n",
    "        else:\n",
    "            if pred < 1:\n",
    "                pred = 1;\n",
    "        Z[u, i] = pred\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the book/user-index dict to index-book/user dict.\n",
    "def convert_dict(dicts):\n",
    "    result = {}\n",
    "    for user in dicts:\n",
    "        result[dicts[user]] = user\n",
    "    return result;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the RMSE for matrix data.\n",
    "def rmse(I, R, M):\n",
    "    count = np.sum(I);\n",
    "    return np.sqrt(np.sum((I * (R - M)) ** 2) / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MAE for matrix data.\n",
    "def mae(I, R, M):\n",
    "    count = np.sum(I);\n",
    "    return np.sum(np.abs(I * (R - M))) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36514\n"
     ]
    }
   ],
   "source": [
    "#Load the book_id to title data\n",
    "poetry_dict = loadFile('poemTitle.json')[0]\n",
    "pprint(len(poetry_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('source_dict.json', 'wt') as file_obj:\n",
    "    json.dump(dict_user, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['22151696', 'Lullabies'],\n",
      "  ['29431081', 'The Universe of Us'],\n",
      "  ['23513349', 'Milk and Honey'],\n",
      "  ['25384844', 'Black Butterfly'],\n",
      "  ['23434371', 'Beautiful Chaos'],\n",
      "  ['13123245', 'B'],\n",
      "  ['13105527', 'I Wrote This For You'],\n",
      "  ['35606560', 'The Sun and Her Flowers'],\n",
      "  ['25746714', 'The Type'],\n",
      "  ['19230408', 'I Wrote This For You: Just the Words'],\n",
      "  ['23534', 'Love Is a Dog from Hell'],\n",
      "  ['18288210', 'No Matter the Wreckage'],\n",
      "  ['29457318', 'Habang Wala Pa Sila: Mga Tula ng Pag-ibig'],\n",
      "  ['13376363', 'Teaching My Mother How to Give Birth'],\n",
      "  ['32468495', 'Pillow Thoughts'],\n",
      "  ['7824768', 'ليتها تقرأ'],\n",
      "  ['6017893', 'قهوة وشيكولاتة'],\n",
      "  ['980426', 'Love Poems'],\n",
      "  ['20821097', 'Chasers of the Light: Poems from the Typewriter Series'],\n",
      "  ['11625', 'Ariel: The Restored Edition'],\n",
      "  ['23522212', 'Mouthful of Forevers'],\n",
      "  ['29758714', 'Dirty Pretty Things'],\n",
      "  ['31443393', 'Note to Self'],\n",
      "  ['6944946', 'يوميات امرأة لا مبالية'],\n",
      "  ['25986828', 'Today Means Amen'],\n",
      "  ['1294049', 'Love Songs'],\n",
      "  ['24688932', 'All The Things I Never Said'],\n",
      "  ['25334576', 'Grief is the Thing with Feathers'],\n",
      "  ['19265831', 'Hello, Baby'],\n",
      "  ['26850255', 'To The Women I Once Loved'],\n",
      "  ['27494', 'Leaves of Grass'],\n",
      "  ['47713', 'Collected Poems, 1912-1944'],\n",
      "  ['400412', 'The Waste Land and Other Poems'],\n",
      "  ['3049', 'Sir Gawain and the Green Knight'],\n",
      "  ['3109162', 'Ballistics'],\n",
      "  ['5868421', 'الرسم بالكلمات'],\n",
      "  ['539143', \"The World Doesn't End\"],\n",
      "  ['34296927', 'I Love My Love'],\n",
      "  ['1434', 'Hamlet'],\n",
      "  ['1371', 'The Iliad'],\n",
      "  ['33667125', 'Lace Bone Beast: Poems & Other Fairytales for Wicked Girls'],\n",
      "  ['42051', 'The Complete Sonnets and Poems'],\n",
      "  ['5865732', 'سيبقى الحب سيدي'],\n",
      "  ['11958571', 'آخر الليل'],\n",
      "  ['12122965', 'أوراق الزيتون'],\n",
      "  ['8098264', 'الخيانة.. مشوار محرج لحد الحزن'],\n",
      "  ['26702564', 'Leave This Song Behind: Teen Poetry at Its Best'],\n",
      "  ['29752702', 'Whiskey Words & a Shovel II'],\n",
      "  ['29335538', 'Lavender'],\n",
      "  ['24717410', 'B']]]\n"
     ]
    }
   ],
   "source": [
    "en = loadFile('rc_po_5_less.json')\n",
    "pprint(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('764332', 4, 'Jason and the Golden Fleece'),\n",
      " ('1519', 4, 'The Oresteia  (Ορέστεια, #1-3)'),\n",
      " ('1715', 4, 'Metamorphoses'),\n",
      " ('12914', 4, 'The Aeneid'),\n",
      " ('1371', 5, 'The Iliad'),\n",
      " ('1381', 5, 'The Odyssey'),\n",
      " ('2696', 4, 'The Canterbury Tales')]\n"
     ]
    }
   ],
   "source": [
    "rate_list = []\n",
    "for i in range(len(book_rate)):\n",
    "    ins = (book_rate[i],train_[target_user][book_rate[i]], poetry_dict[book_rate[i]])\n",
    "    rate_list.append(ins)\n",
    "pprint(rate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('22151696', 'Lullabies'),\n",
      " ('29431081', 'The Universe of Us'),\n",
      " ('23513349', 'Milk and Honey'),\n",
      " ('25384844', 'Black Butterfly'),\n",
      " ('23434371', 'Beautiful Chaos'),\n",
      " ('13123245', 'B'),\n",
      " ('13105527', 'I Wrote This For You'),\n",
      " ('35606560', 'The Sun and Her Flowers'),\n",
      " ('25746714', 'The Type'),\n",
      " ('19230408', 'I Wrote This For You: Just the Words'),\n",
      " ('23534', 'Love Is a Dog from Hell'),\n",
      " ('18288210', 'No Matter the Wreckage'),\n",
      " ('29457318', 'Habang Wala Pa Sila: Mga Tula ng Pag-ibig'),\n",
      " ('13376363', 'Teaching My Mother How to Give Birth'),\n",
      " ('32468495', 'Pillow Thoughts'),\n",
      " ('7824768', 'ليتها تقرأ'),\n",
      " ('6017893', 'قهوة وشيكولاتة'),\n",
      " ('980426', 'Love Poems'),\n",
      " ('20821097', 'Chasers of the Light: Poems from the Typewriter Series'),\n",
      " ('11625', 'Ariel: The Restored Edition'),\n",
      " ('23522212', 'Mouthful of Forevers'),\n",
      " ('29758714', 'Dirty Pretty Things'),\n",
      " ('31443393', 'Note to Self'),\n",
      " ('6944946', 'يوميات امرأة لا مبالية'),\n",
      " ('25986828', 'Today Means Amen'),\n",
      " ('1294049', 'Love Songs'),\n",
      " ('24688932', 'All The Things I Never Said'),\n",
      " ('25334576', 'Grief is the Thing with Feathers'),\n",
      " ('19265831', 'Hello, Baby'),\n",
      " ('26850255', 'To The Women I Once Loved'),\n",
      " ('27494', 'Leaves of Grass'),\n",
      " ('47713', 'Collected Poems, 1912-1944'),\n",
      " ('400412', 'The Waste Land and Other Poems'),\n",
      " ('3049', 'Sir Gawain and the Green Knight'),\n",
      " ('3109162', 'Ballistics'),\n",
      " ('5868421', 'الرسم بالكلمات'),\n",
      " ('539143', \"The World Doesn't End\"),\n",
      " ('34296927', 'I Love My Love'),\n",
      " ('1434', 'Hamlet'),\n",
      " ('1371', 'The Iliad'),\n",
      " ('33667125', 'Lace Bone Beast: Poems & Other Fairytales for Wicked Girls'),\n",
      " ('42051', 'The Complete Sonnets and Poems'),\n",
      " ('5865732', 'سيبقى الحب سيدي'),\n",
      " ('11958571', 'آخر الليل'),\n",
      " ('12122965', 'أوراق الزيتون'),\n",
      " ('8098264', 'الخيانة.. مشوار محرج لحد الحزن'),\n",
      " ('26702564', 'Leave This Song Behind: Teen Poetry at Its Best'),\n",
      " ('29752702', 'Whiskey Words & a Shovel II'),\n",
      " ('29335538', 'Lavender'),\n",
      " ('24717410', 'B')]\n"
     ]
    }
   ],
   "source": [
    "res_list = []\n",
    "for i in range(len(book_list)):\n",
    "    ins = (book_list[i], poetry_dict[book_list[i]])\n",
    "    res_list.append(ins)\n",
    "pprint(res_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "pprint(len(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rc_po_5_less.json', 'wt') as file_obj:\n",
    "    json.dump(res_list, file_obj)\n",
    "\n",
    "#with open('rc_po_rate_4.json', 'wt') as file_obj:\n",
    "#    json.dump(rate_list, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10041732': 'Core Samples from the World',\n",
      " '104831': 'آرش کمانگیر',\n",
      " '1056805': 'Sir Gawain and the Green Knight: A New Verse Translation',\n",
      " '1089337': 'Words for the Wind: The Collected Verse',\n",
      " '111044': 'Stop Pretending: What Happened When My Big Sister Went Crazy',\n",
      " '11255697': 'مهندس العالم',\n",
      " '113209': 'The Best of Robert Service',\n",
      " '1160501': 'The Ballad of the White Horse',\n",
      " '120724': 'Selected Poems',\n",
      " '12352685': 'The Wild Book',\n",
      " '12429335': 'Water Sings Blue: Ocean Poems',\n",
      " '12675105': 'Balloon Pop Outlaw Black',\n",
      " '1330089': 'Oh Forbidden',\n",
      " '1371100': 'The Great Poets: Rudyard Kipling',\n",
      " '1388192': 'The Elder Edda: A Book of Viking Lore',\n",
      " '141600': 'Doré\\'s Illustrations for \"Paradise Lost\"',\n",
      " '152532': 'Auden: Poems',\n",
      " '165251': 'Song of the Simple Truth: The Complete Poems of Julia de Burgos',\n",
      " '1785216': 'Mahabharata',\n",
      " '178746': 'The Selected Poetry of Yevgeny Yevtushenko',\n",
      " '18901': 'The Book of Nightmares',\n",
      " '193603': 'The Complete Poems',\n",
      " '20658': 'Blind Huber',\n",
      " '2355014': 'Ozymandias',\n",
      " '236188': 'One Hundred Poems from the Chinese',\n",
      " '295149': 'Selected Poems',\n",
      " '304433': 'Women Poets of China',\n",
      " '3348584': 'Blood Dazzler',\n",
      " '46231': 'The Portable Dorothy Parker',\n",
      " '50479': 'Twenty Prose Poems',\n",
      " '515187': 'Smoke',\n",
      " '57628': 'Migration: New and Selected Poems',\n",
      " '584302': 'The Vintage Book of Contemporary World Poetry',\n",
      " '6061538': 'Plumb',\n",
      " '6421376': 'Practical Water',\n",
      " '657504': 'گزینه اشعار مهدی اخوان ثالث',\n",
      " '661715': \"If You're Not Here, Please Raise Your Hand: Poems About School\",\n",
      " '7083492': 'The Canterbury Tales (Barnes & Noble Classics Series)',\n",
      " '7156792': 'Last Looks, Last Books: Stevens, Plath, Lowell, Bishop, Merrill',\n",
      " '732112': 'The Libertine',\n",
      " '752886': 'Selected Poems',\n",
      " '75494': 'The Complete Poems',\n",
      " '761271': 'Lyrics: 1962-2001',\n",
      " '7953223': 'Astrophel and Stella',\n",
      " '857449': 'Intimate Kisses: The Poetry of Sexual Pleasure',\n",
      " '881508': 'Pan Tadeusz',\n",
      " '8850512': 'Each and Her',\n",
      " '897487': 'Gulf Music: Poems',\n",
      " '936208': 'Serious Concerns',\n",
      " '9748346': 'الأعمال الكاملة'}\n"
     ]
    }
   ],
   "source": [
    "rc = loadFile('rcTitle_new.json')[0]\n",
    "pprint(rc)\n",
    "rc_list = []\n",
    "for meta in rc:\n",
    "    rc_li\n",
    "    rc_list.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = ('1785216', '7083492', '881508', '104831')\n",
    "set2 = ('1160501','1388192','141600','2355014','236188','46231','304433','50479','6061538','752886','75494','7953223')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_re_list = []\n",
    "for i in range(len(book_list)):\n",
    "    if book_list[i] in set1:\n",
    "        book_re_list.append(book_list[i])\n",
    "\n",
    "for i in range(len(book_list)):\n",
    "    if book_list[i] in set2:\n",
    "        book_re_list.append(book_list[i])\n",
    "        \n",
    "for i in range(len(book_list)):\n",
    "    if (book_list[i] not in set1) and (book_list[i] not in set2):\n",
    "        book_re_list.append(book_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "pprint(len(book_re_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rc_po_2.json', 'wt') as file_obj:\n",
    "    json.dump(book_re_list, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ly = []\n",
    "book_st = []\n",
    "for i in range(50):\n",
    "    if i < 25:\n",
    "        book_ly.append(rc_list[i])\n",
    "    else:\n",
    "        book_st.append(rc_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['295149',\n",
      " '7083492',\n",
      " '193603',\n",
      " '120724',\n",
      " '20658',\n",
      " '732112',\n",
      " '761271',\n",
      " '50479',\n",
      " '1388192',\n",
      " '1089337',\n",
      " '657504',\n",
      " '236188',\n",
      " '8850512',\n",
      " '10041732',\n",
      " '46231',\n",
      " '1330089',\n",
      " '897487',\n",
      " '104831',\n",
      " '3348584',\n",
      " '1785216',\n",
      " '881508',\n",
      " '1371100',\n",
      " '111044',\n",
      " '165251',\n",
      " '6421376']\n"
     ]
    }
   ],
   "source": [
    "pprint(book_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13568\n"
     ]
    }
   ],
   "source": [
    "bookList = loadFile('mix_data.json')\n",
    "idSet = set();\n",
    "for meta in bookList:\n",
    "    idSet.add(meta['book_id']);\n",
    "pprint(len(idSet));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'asin': 'B00NLXQ534',\n",
      " 'authors': [{'author_id': '8551671', 'role': ''}],\n",
      " 'average_rating': '4.12',\n",
      " 'book_id': '25742454',\n",
      " 'country_code': 'US',\n",
      " 'description': 'Lillian Ann Cross is forced to live the worst nightmare of '\n",
      "                'her life. She is an everyday middle class American, striving '\n",
      "                'to survive in an everyday changing world. Her life was '\n",
      "                'abruptly<br />turned upsidedown forever as she was kidnapped '\n",
      "                'and forced into a world called \"Hen Fighting.\"<br /><br />A '\n",
      "                'world in which women fight and bets are made upon their '\n",
      "                'bloodshed.Lillian is forced to comply due to the threats made '\n",
      "                \"upon her mother's life. Being a loving person her whole life, \"\n",
      "                'Lillian finds difficulty grasping her new functions. As she '\n",
      "                'is conditioned to live in her new world, she is subjected to '\n",
      "                'an experimental procedure. A procedure which has taken the '\n",
      "                'lives of a few before her. As she survives, she now has to '\n",
      "                'learn how to live with her new \"implants.\" Implants which '\n",
      "                'strengthen her bones, giving her strength and an upper '\n",
      "                'ability amongst others. Implants which require weekly '\n",
      "                'sustenance, or she will die.',\n",
      " 'edition_information': ' ',\n",
      " 'format': ' ',\n",
      " 'image_url': 'https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png',\n",
      " 'is_ebook': 'true',\n",
      " 'isbn': ' ',\n",
      " 'isbn13': ' ',\n",
      " 'kindle_asin': ' ',\n",
      " 'language_code': '',\n",
      " 'link': 'https://www.goodreads.com/book/show/25742454-the-switchblade-mamma',\n",
      " 'num_pages': ' ',\n",
      " 'popular_shelves': [{'count': '228', 'name': 'to-read'},\n",
      "                     {'count': '2', 'name': 'graphic-novels'},\n",
      "                     {'count': '1', 'name': 'ff-re-2011-till-2015'},\n",
      "                     {'count': '1', 'name': 'calibre-list'},\n",
      "                     {'count': '1', 'name': 'linseyschussan'},\n",
      "                     {'count': '1', 'name': '1-person-narrative'},\n",
      "                     {'count': '1', 'name': 'lgbtq-ya'},\n",
      "                     {'count': '1', 'name': 'watchlist'},\n",
      "                     {'count': '1', 'name': 'next-to-read'},\n",
      "                     {'count': '1', 'name': 'sf'},\n",
      "                     {'count': '1', 'name': 'sachiko'},\n",
      "                     {'count': '1', 'name': 'giveaway-add'},\n",
      "                     {'count': '1', 'name': 'friends-in-mind'},\n",
      "                     {'count': '1',\n",
      "                      'name': 'free-to-read-or-preview-on-goodread'},\n",
      "                     {'count': '1', 'name': 'fantasy'},\n",
      "                     {'count': '1', 'name': 'dystopian'},\n",
      "                     {'count': '1', 'name': 'ck-library'},\n",
      "                     {'count': '1',\n",
      "                      'name': '23089-ya-fantasy-sf-w-major-lgbt'}],\n",
      " 'publication_day': '',\n",
      " 'publication_month': '',\n",
      " 'publication_year': '',\n",
      " 'publisher': '',\n",
      " 'ratings_count': '1',\n",
      " 'series': [],\n",
      " 'similar_books': ['25653153',\n",
      "                   '25699172',\n",
      "                   '23530486',\n",
      "                   '12984185',\n",
      "                   '25538377',\n",
      "                   '23525552',\n",
      "                   '18215952',\n",
      "                   '21412122',\n",
      "                   '25758901'],\n",
      " 'text_reviews_count': '1',\n",
      " 'url': 'https://www.goodreads.com/book/show/25742454-the-switchblade-mamma',\n",
      " 'work_id': '42749946'}\n"
     ]
    }
   ],
   "source": [
    "pprint(bookList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10894849\n",
      "3224278\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "idList = [];\n",
    "idDict = {};\n",
    "idConv = {}\n",
    "count = 0;\n",
    "for bookid in idSet:\n",
    "    idList.append(bookid)\n",
    "    idDict[bookid] = count\n",
    "    idConv[count] = bookid\n",
    "    count += 1;\n",
    "print(idList[0])\n",
    "print(idConv[1])\n",
    "print(idDict['10894849'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'goodreads_interactions_poetry.json'\n",
      "59452\n",
      "'goodreads_interactions_children.json'\n",
      "58555\n",
      "'goodreads_interactions_comics_graphic.json'\n",
      "63603\n",
      "'goodreads_interactions_fantasy_paranormal.json'\n",
      "70000\n",
      "'goodreads_interactions_history_biography.json'\n",
      "70000\n",
      "'goodreads_interactions_mystery_thriller_crime.json'\n",
      "70000\n",
      "'goodreads_interactions_romance.json'\n",
      "70000\n",
      "'goodreads_interactions_young_adult.json'\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "dataUserMeta1 = loadFileDict('goodreads_interactions_poetry.json', idSet)\n",
    "dataUserMeta2 = loadFileDict('goodreads_interactions_children.json', idSet)\n",
    "dataUserMeta3 = loadFileDict('goodreads_interactions_comics_graphic.json', idSet)\n",
    "dataUserMeta4 = loadFileDict('goodreads_interactions_fantasy_paranormal.json', idSet)\n",
    "dataUserMeta5 = loadFileDict('goodreads_interactions_history_biography.json', idSet)\n",
    "dataUserMeta6 = loadFileDict('goodreads_interactions_mystery_thriller_crime.json', idSet)\n",
    "dataUserMeta7 = loadFileDict('goodreads_interactions_romance.json', idSet)\n",
    "dataUserMeta8 = loadFileDict('goodreads_interactions_young_adult.json', idSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267739\n"
     ]
    }
   ],
   "source": [
    "#全部写完后合并数据集\n",
    "dict_all = {}\n",
    "dict_all = mergedata(dict_all, dataUserMeta1)\n",
    "dict_all = mergedata(dict_all, dataUserMeta2)\n",
    "dict_all = mergedata(dict_all, dataUserMeta3)\n",
    "dict_all = mergedata(dict_all, dataUserMeta4)\n",
    "dict_all = mergedata(dict_all, dataUserMeta5)\n",
    "dict_all = mergedata(dict_all, dataUserMeta6)\n",
    "dict_all = mergedata(dict_all, dataUserMeta7)\n",
    "dict_all = mergedata(dict_all, dataUserMeta8)\n",
    "pprint(len(dict_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267739\n"
     ]
    }
   ],
   "source": [
    "#对数据进行储存，并且进行写入验证\n",
    "with open('user.json', 'wt') as file_obj:\n",
    "    json.dump(dict_all, file_obj)\n",
    "\n",
    "datas = []\n",
    "with open('user.json') as f:\n",
    "    for line in f:\n",
    "        datas = json.loads(line)\n",
    "    f.close()\n",
    "pprint(len(datas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15389\n"
     ]
    }
   ],
   "source": [
    "dict_re = {};\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['isRead']) >= 5:\n",
    "        dict_re[user] = dict_all[user]\n",
    "pprint(len(dict_re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割两个数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'b03f5b741a7b3b8e4a79eb76a99a6860'\n",
      "['178911',\n",
      " '587318',\n",
      " '1085771',\n",
      " '477338',\n",
      " '137918',\n",
      " '129655',\n",
      " '179176',\n",
      " '15801762']\n",
      "[5, 5, 5, 4, 2, 1, 5, 5]\n"
     ]
    }
   ],
   "source": [
    "#找到目标用户\n",
    "for user in dict_user:\n",
    "    if len(dict_user[user]['rate']) > 7:\n",
    "        target_user = user\n",
    "        break;\n",
    "pprint(target_user)\n",
    "\n",
    "target_book = dict_user[target_user]['book_id']\n",
    "target_rating = dict_user[target_user]['rate']\n",
    "pprint(target_book)\n",
    "pprint(target_rating)\n",
    "if target_user in dict_remain:\n",
    "    pprint(dict_remain[target_user]['book_id'])\n",
    "if target_user in dict_unknown:\n",
    "    pprint(dict_unknown[target_user]['book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_re['b03f5b741a7b3b8e4a79eb76a99a6860']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对用户进行分析： 和划分集合重复\n",
    "train_dict = dict_user\n",
    "test_dict = {}\n",
    "test_dict[target_user] = {}\n",
    "test_dict[target_user]['book_id'] = []\n",
    "test_dict[target_user]['rate'] = []\n",
    "for book in idSet:\n",
    "    if book not in dict_all[target_user]['book_id']:\n",
    "        test_dict[target_user]['book_id'].append(book)\n",
    "        test_dict[target_user]['rate'].append(0)\n",
    "\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "res = pred_test_im(train_, test_, 100000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "'8369681'\n",
      "13559\n"
     ]
    }
   ],
   "source": [
    "#print(len(dict_unknown))\n",
    "pprint(len(res))\n",
    "result = res[target_user]\n",
    "sorted_x=sorted(result.items(), key = operator.itemgetter(1))\n",
    "#pprint(sorted_x[len(sorted_x) - 1])\n",
    "start = len(sorted_x) - 51;\n",
    "end = len(sorted_x) - 1;\n",
    "pprint(sorted_x[end][0])\n",
    "result_id = []\n",
    "for i in range(end, start, -1):\n",
    "    if i == end:\n",
    "        print(i)\n",
    "    if i == start:\n",
    "        print(i)\n",
    "    result_id.append(sorted_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "id_list = []\n",
    "for i in range(len(result_id)):\n",
    "    id_list.append(result_id[i][0])\n",
    "pprint(len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_id': ['178911',\n",
      "             '587318',\n",
      "             '1085771',\n",
      "             '477338',\n",
      "             '137918',\n",
      "             '129655',\n",
      "             '179176',\n",
      "             '15801762'],\n",
      " 'rate': [5, 5, 5, 4, 2, 1, 5, 5],\n",
      " 'user_id': 'b03f5b741a7b3b8e4a79eb76a99a6860'}\n"
     ]
    }
   ],
   "source": [
    "user_info = {}\n",
    "user_info['user_id'] = target_user;\n",
    "user_info['book_id'] = dict_user[target_user]['book_id']\n",
    "user_info['rate'] = dict_user[target_user]['rate']\n",
    "\n",
    "with open('user_info.json', 'wt') as file_obj:\n",
    "    json.dump(user_info, file_obj)\n",
    "\n",
    "data_in_user = []\n",
    "with open('user_info.json') as f:\n",
    "    for line in f:\n",
    "        data_in_user = json.loads(line)\n",
    "    f.close()\n",
    "pprint(data_in_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The title:  Annabel Lee\n",
      "The rating: 5\n",
      "The title:  The Last Battle (The Chronicles of Narnia, #7)\n",
      "The rating: 5\n",
      "The title:  The Walking Dead, Vol. 07: The Calm Before\n",
      "The rating: 5\n",
      "The title:  Blue is for Nightmares (Blue is for Nightmares, #1)\n",
      "The rating: 4\n",
      "The title:  More, Now, Again: A Memoir of Addiction\n",
      "The rating: 2\n",
      "The title:  The Fatal Fashione (Elizabeth I, #8)\n",
      "The rating: 1\n",
      "The title:  The Werewolf's Sin (Voodoo Moon, #3)\n",
      "The rating: 5\n",
      "The title:  Zom-B Angels\n",
      "The rating: 5\n"
     ]
    }
   ],
   "source": [
    "title_dict = loadFile('title.json')[0]\n",
    "title_list = []\n",
    "for book in user_info['book_id']:\n",
    "    title_list.append(title_dict[book])\n",
    "for i in range(len(title_list)):\n",
    "    print('The title: ', title_list[i]);\n",
    "    print('The rating:', user_info['rate'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prom and Prejudice',\n",
      " 'Revenant (Buffy the Vampire Slayer: Season 3, #11)',\n",
      " \"Don't Let the Pigeon Drive the Bus!\",\n",
      " 'I Know What You Did Last Summer',\n",
      " 'The Worry Week',\n",
      " 'The Pleasures of the Damned',\n",
      " 'The Name of the Wind (The Kingkiller Chronicle, #1)',\n",
      " 'Claire de Lune (Claire de Lune, #1)',\n",
      " 'Bons Sonhos, Meu Amor',\n",
      " 'Strangers',\n",
      " '50 Below Zero',\n",
      " 'Le due guerriere (Le Guerre del Mondo Emerso #2)',\n",
      " \"Emily's Secret Book of Strange (Emily the Strange Graphic Novels, #2)\",\n",
      " 'MARS: Horse With No Name',\n",
      " 'William Wilson',\n",
      " 'The Paris Wife',\n",
      " 'Shadowlands',\n",
      " 'The Legend of the Poinsettia',\n",
      " 'Born a Crime: Stories From a South African Childhood',\n",
      " 'A Northern Light',\n",
      " 'rock',\n",
      " \"Don't Ever Change\",\n",
      " 'Nightwing #5 (Nightwing 2016, #5)',\n",
      " 'A Little Something Different',\n",
      " 'Good-Bye, Chunky Rice',\n",
      " 'Injustice: Gods Among Us #24',\n",
      " \"Baby-sitters' Island Adventure (The Baby-Sitters Club Super Special, #4)\",\n",
      " \"There's Someone Inside Your House\",\n",
      " 'Abraham Lincoln: Vampire Hunter',\n",
      " 'Beauty and the Beast',\n",
      " 'Babymouse: The Musical (Babymouse, #10)',\n",
      " 'Alex + Ada, Vol. 1',\n",
      " 'Killing Reagan: The Violent Assault That Changed a Presidency',\n",
      " 'Lightning',\n",
      " 'Blood+ Adagio, Vol. 02 (Blood+ Adagio, #2)',\n",
      " 'The Black Angel (Charlie Parker, #5)',\n",
      " \"The Queen's Army (The Lunar Chronicles, #1.5)\",\n",
      " 'Forever with You (Wait for You, #5)',\n",
      " 'Stop Pretending: What Happened When My Big Sister Went Crazy',\n",
      " 'Pluk van de Petteflet',\n",
      " 'Throne of Jade (Temeraire, #2)',\n",
      " 'The Librarian from the Black Lagoon (Black Lagoon, #5)',\n",
      " 'Uglen (Holger Munch og Mia Kruger #2)',\n",
      " 'Journals: Early Fifties, Early Sixties',\n",
      " 'Light on Lucrezia (Lucrezia Borgia, #2)',\n",
      " 'Wallbanger (Cocktail, #1)',\n",
      " 'Books of Blood, Volumes 4-6',\n",
      " 'IF Anthology: Super Powers',\n",
      " '聖闘士星矢 THE LOST CANVAS 冥王神話 外伝 3 (Saint Seiya The Lost Canvas Gaiden, #3)',\n",
      " 'Gone Too Far']\n"
     ]
    }
   ],
   "source": [
    "rc_list = []\n",
    "for book in id_list:\n",
    "    rc_list.append(title_dict[book])\n",
    "pprint(rc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8369681',\n",
      " '293450',\n",
      " '191113',\n",
      " '47763',\n",
      " '835990',\n",
      " '220682',\n",
      " '186074',\n",
      " '6658573',\n",
      " '6396080',\n",
      " '15676',\n",
      " '560262',\n",
      " '9703431',\n",
      " '424604',\n",
      " '543980',\n",
      " '6798492',\n",
      " '8683812',\n",
      " '17428654',\n",
      " '14063',\n",
      " '29780253',\n",
      " '64481',\n",
      " '23153351',\n",
      " '23361053',\n",
      " '30740909',\n",
      " '20801166',\n",
      " '37264',\n",
      " '18131324',\n",
      " '290512',\n",
      " '15797848',\n",
      " '9421274',\n",
      " '6629481',\n",
      " '3922195',\n",
      " '21823465',\n",
      " '25624089',\n",
      " '1406392',\n",
      " '6536909',\n",
      " '175245',\n",
      " '16093690',\n",
      " '24357334',\n",
      " '111044',\n",
      " '2854614',\n",
      " '14069',\n",
      " '111002',\n",
      " '27246906',\n",
      " '226946',\n",
      " '1327609',\n",
      " '20582289',\n",
      " '108064',\n",
      " '29501904',\n",
      " '16117517',\n",
      " '23267836']\n"
     ]
    }
   ],
   "source": [
    "with open('rc_book_id.json', 'wt') as file_obj:\n",
    "    json.dump(id_list, file_obj)\n",
    "\n",
    "data_in_id = []\n",
    "with open('rc_book_id.json') as f:\n",
    "    for line in f:\n",
    "        data_in_id = json.loads(line)\n",
    "    f.close()\n",
    "pprint(data_in_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3fead09d45d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbookMeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'goodreads_interactions_poetry.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loadFile' is not defined"
     ]
    }
   ],
   "source": [
    "bookMeta = loadFile('goodreads_interactions_poetry.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_all = {}\n",
    "rate_all = {}\n",
    "for meta in bookMeta:\n",
    "    book_id = meta['book_id']\n",
    "    if book_id in book_list:\n",
    "        rc_all.append(rc_all)\n",
    "    if book_id in book_rate:\n",
    "        rc_all.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMetaAll = loadFile('goodreads_interactions_poetry.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDict = transToDict(dataMetaAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_all = dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282415\n",
      "36374\n"
     ]
    }
   ],
   "source": [
    "#先build两个Index\n",
    "user_index = buildUserIndex(dict_all)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_all);\n",
    "pprint(len(book_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'80d52f5e70f023bd0098ab96599a3530'\n",
      "{'book_id': ['23913',\n",
      "             '47180',\n",
      "             '563782',\n",
      "             '19351',\n",
      "             '20413',\n",
      "             '65336',\n",
      "             '304079',\n",
      "             '402128',\n",
      "             '72155',\n",
      "             '782580',\n",
      "             '95819',\n",
      "             '112204',\n",
      "             '23919',\n",
      "             '142080',\n",
      "             '99944',\n",
      "             '2547',\n",
      "             '30118',\n",
      "             '534647',\n",
      "             '6295',\n",
      "             '30119',\n",
      "             '46231'],\n",
      " 'isRead': [True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True,\n",
      "            True],\n",
      " 'rate': [4, 4, 4, 4, 4, 3, 3, 4, 5, 5, 5, 5, 5, 5, 4, 4, 5, 4, 5, 5, 4]}\n"
     ]
    }
   ],
   "source": [
    "user_more = 0;\n",
    "count = 0\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['book_id']) > 20:\n",
    "        count += 1\n",
    "        user_more = user\n",
    "        if count > 9:\n",
    "            break;\n",
    "pprint(user_more)\n",
    "pprint(dict_all[user_more])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The Marriage of Heaven and Hell'\n",
      "'Kaddish and Other Poems'\n",
      "'Collected Poems, 1947-1980'\n",
      "'The Epic of Gilgamesh'\n",
      "\"A Child's Garden of Verses\"\n",
      "'Selected Poems'\n",
      "'The Essential Rumi'\n",
      "\"Old Possum's Book of Practical Cats\"\n",
      "'The Collected Poems, Vol. 1: 1909-1939'\n",
      "'The Complete Poetry and Prose'\n",
      "'The Poetry of Robert Frost'\n",
      "'The Complete Poems of Emily Dickinson'\n",
      "'The Complete Stories and Poems'\n",
      "'Collected Poems, 1909-1962'\n",
      "'The Bhagavad Gita'\n",
      "'The Prophet'\n",
      "'A Light in the Attic'\n",
      "'The Portable Beat Reader'\n",
      "'Howl and Other Poems'\n",
      "'Where the Sidewalk Ends'\n",
      "'The Portable Dorothy Parker'\n"
     ]
    }
   ],
   "source": [
    "for book in dict_all[user_more]['book_id']:\n",
    "    pprint(poetry_dict[book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fab3e0cea61720dc85881bfc09d06b97'\n",
      "{'book_id': ['34023590', '25330489', '18003300'],\n",
      " 'isRead': [True, True, True],\n",
      " 'rate': [2, 4, 3]}\n"
     ]
    }
   ],
   "source": [
    "user_min = 0;\n",
    "count = 0\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['book_id']) == 3:\n",
    "        count += 1\n",
    "        user_min = user\n",
    "        if count > 20:\n",
    "            break;\n",
    "pprint(user_min)\n",
    "pprint(dict_all[user_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Sad Girls'\n",
      "'Memories'\n",
      "'Love & Misadventure'\n"
     ]
    }
   ],
   "source": [
    "for book in dict_all[user_min]['book_id']:\n",
    "    pprint(poetry_dict[book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rate': {'18003300': 3, '25330489': 4, '34023590': 2},\n",
      " 'user_id': 'fab3e0cea61720dc85881bfc09d06b97'}\n"
     ]
    }
   ],
   "source": [
    "#'1fa34209b2a0797942f7961ca8d69e2e'\n",
    "dict_less = {}\n",
    "dict_less['user_id'] = user_min\n",
    "dict_less['rate'] = {}\n",
    "for i in range(len(dict_all[user_min]['book_id'])):\n",
    "    dict_less['rate'][dict_all[user_min]['book_id'][i]] = dict_all[user_min]['rate'][i]\n",
    "pprint(dict_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rate': {'12914': 4,\n",
      "          '1371': 5,\n",
      "          '1381': 5,\n",
      "          '1519': 4,\n",
      "          '1715': 4,\n",
      "          '2696': 4,\n",
      "          '764332': 4},\n",
      " 'user_id': '26b5bed05bcabbabdaec4ee08fc43244'}\n"
     ]
    }
   ],
   "source": [
    "dict_more = {}\n",
    "dict_more['user_id'] = '26b5bed05bcabbabdaec4ee08fc43244'\n",
    "user_more = '26b5bed05bcabbabdaec4ee08fc43244'\n",
    "dict_more['rate'] = {}\n",
    "for i in range(len(dict_all[user_more]['book_id'])):\n",
    "    dict_more['rate'][dict_all[user_more]['book_id'][i]] = dict_all[user_more]['rate'][i]\n",
    "pprint(dict_more)\n",
    "for book in dict_all[user_more]['book_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'764332'\n",
      "'Jason and the Golden Fleece'\n",
      "'1519'\n",
      "'The Oresteia  (Ορέστεια, #1-3)'\n",
      "'1715'\n",
      "'Metamorphoses'\n",
      "'12914'\n",
      "'The Aeneid'\n",
      "'1371'\n",
      "'The Iliad'\n",
      "'1381'\n",
      "'The Odyssey'\n",
      "'2696'\n",
      "'The Canterbury Tales'\n",
      "'764332'\n",
      "'Jason and the Golden Fleece'\n",
      "'1519'\n",
      "'The Oresteia  (Ορέστεια, #1-3)'\n",
      "'1715'\n",
      "'Metamorphoses'\n",
      "'12914'\n",
      "'The Aeneid'\n",
      "'1371'\n",
      "'The Iliad'\n"
     ]
    }
   ],
   "source": [
    "for book in dict_all[user_more]['book_id']:\n",
    "    pprint(book)\n",
    "    pprint(poetry_dict[book])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rate': {'18003300': 3, '25330489': 4, '34023590': 2},\n",
      "  'user_id': 'fab3e0cea61720dc85881bfc09d06b97'},\n",
      " {'rate': {'12914': 4,\n",
      "           '1371': 5,\n",
      "           '1381': 5,\n",
      "           '1519': 4,\n",
      "           '1715': 4,\n",
      "           '2696': 4,\n",
      "           '764332': 4},\n",
      "  'user_id': '26b5bed05bcabbabdaec4ee08fc43244'}]\n"
     ]
    }
   ],
   "source": [
    "restore = []\n",
    "restore.append(dict_less)\n",
    "restore.append(dict_more)\n",
    "pprint(restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('two_user_end.json', 'wt') as file_obj:\n",
    "    json.dump(restore, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n"
     ]
    }
   ],
   "source": [
    "dict_re = {};\n",
    "for user in dict_all:\n",
    "    if len(dict_all[user]['isRead']) >= 10 or user == user_min:\n",
    "        dict_re[user] = dict_all[user]\n",
    "pprint(len(dict_re)) #把User_min加进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1fa34209b2a0797942f7961ca8d69e2e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-ca38484a6573>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_re\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1fa34209b2a0797942f7961ca8d69e2e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '1fa34209b2a0797942f7961ca8d69e2e'"
     ]
    }
   ],
   "source": [
    "pprint(dict_re['1fa34209b2a0797942f7961ca8d69e2e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n",
      "33926\n",
      "27873\n"
     ]
    }
   ],
   "source": [
    "array_2 = []\n",
    "array_2 = sep_data(dict_re)\n",
    "dict_user = array_2[0]\n",
    "dict_remain = array_2[1]\n",
    "dict_unknown = array_2[2]\n",
    "\n",
    "target_user = 'fab3e0cea61720dc85881bfc09d06b97'\n",
    "\n",
    "user_index = buildUserIndex(dict_re)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_re);\n",
    "pprint(len(book_index))\n",
    "\n",
    "train_dict = dict_user\n",
    "test_dict = {}\n",
    "test_dict[target_user] = {}\n",
    "test_dict[target_user]['book_id'] = []\n",
    "test_dict[target_user]['rate'] = []\n",
    "\n",
    "for book in book_index:\n",
    "    if book not in dict_all[target_user]['book_id']:\n",
    "        test_dict[target_user]['book_id'].append(book)\n",
    "        test_dict[target_user]['rate'].append(1)\n",
    "\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "\n",
    "pprint(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_id': ['34023590', '25330489', '18003300'], 'rate': [2, 4, 3]}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict_user[target_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27873\n"
     ]
    }
   ],
   "source": [
    "pprint(len(dict_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n",
      "36374\n"
     ]
    }
   ],
   "source": [
    "user_index = buildUserIndex(dict_re)\n",
    "pprint(len(user_index))\n",
    "book_index = buildBookIndex(dict_all);\n",
    "pprint(len(book_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1fa34209b2a0797942f7961ca8d69e2e'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-c1bfa2b886b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1fa34209b2a0797942f7961ca8d69e2e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '1fa34209b2a0797942f7961ca8d69e2e'"
     ]
    }
   ],
   "source": [
    "pprint(train_['1fa34209b2a0797942f7961ca8d69e2e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pred_test_im(train_, test_, 1000000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33923\n"
     ]
    }
   ],
   "source": [
    "for i in res:\n",
    "    result = res[i]\n",
    "pprint(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x=sorted(result.items(), key = operator.itemgetter(1))\n",
    "start = len(sorted_x) - 51;\n",
    "end = len(sorted_x) - 1;\n",
    "#pprint(sorted_x[end][0])\n",
    "result_id = []\n",
    "for i in range(end, start, -1):\n",
    "    result_id.append(sorted_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19230408', 3.057364807746158)\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted_x[len(sorted_x) - 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36367\n"
     ]
    }
   ],
   "source": [
    "pprint(len(sorted_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22151696',\n",
      " '29431081',\n",
      " '23513349',\n",
      " '25384844',\n",
      " '23434371',\n",
      " '13123245',\n",
      " '13105527',\n",
      " '35606560',\n",
      " '25746714',\n",
      " '19230408',\n",
      " '23534',\n",
      " '18288210',\n",
      " '29457318',\n",
      " '13376363',\n",
      " '32468495',\n",
      " '7824768',\n",
      " '6017893',\n",
      " '980426',\n",
      " '20821097',\n",
      " '11625',\n",
      " '23522212',\n",
      " '29758714',\n",
      " '31443393',\n",
      " '6944946',\n",
      " '25986828',\n",
      " '1294049',\n",
      " '24688932',\n",
      " '25334576',\n",
      " '19265831',\n",
      " '26850255',\n",
      " '27494',\n",
      " '47713',\n",
      " '400412',\n",
      " '3049',\n",
      " '3109162',\n",
      " '5868421',\n",
      " '539143',\n",
      " '34296927',\n",
      " '1434',\n",
      " '1371',\n",
      " '33667125',\n",
      " '42051',\n",
      " '5865732',\n",
      " '11958571',\n",
      " '12122965',\n",
      " '8098264',\n",
      " '26702564',\n",
      " '29752702',\n",
      " '29335538',\n",
      " '24717410']\n",
      "['34023590', '25330489', '18003300']\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "book_list = []\n",
    "for i in range(50):\n",
    "    book_list.append(result_id[i][0])\n",
    "pprint(book_list)\n",
    "book_rate = []\n",
    "for book_id in train_[target_user]:\n",
    "    book_rate.append(book_id)\n",
    "pprint(book_rate)\n",
    "print(len(book_list))\n",
    "#book_list.extend(book_rate)\n",
    "#pprint(book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rc_po_1.json', 'wt') as file_obj:\n",
    "    json.dump(book_list, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rc_po_3.json', 'wt') as file_obj:\n",
    "    json.dump(book_list, file_obj)\n",
    "\n",
    "with open('rc_po_rate_1.json', 'wt') as file_obj:\n",
    "    json.dump(book_rate, file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12914': 4, '1371': 5, '1381': 5, '1519': 4, '1715': 4, '2696': 4, '764332': 4}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_[target_user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27873\n"
     ]
    }
   ],
   "source": [
    "#完全转化为dict-dict 第一个key是user的名字，第二个key是book的名字\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "#userset = get_set([],train_dict);\n",
    "print(len(train_))\n",
    "#print(train_['8842281e1d1347389f2ab93d60773d4d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['34023590', '25330489', '18003300']\n",
      "[2, 4, 3]\n",
      "27873\n",
      "27873\n"
     ]
    }
   ],
   "source": [
    "#划分测试集和数据集\n",
    "\n",
    "target_book = dict_user[target_user]['book_id']\n",
    "target_rating = dict_user[target_user]['rate']\n",
    "pprint(target_book)\n",
    "pprint(target_rating)\n",
    "if target_user in dict_remain:\n",
    "    pprint(dict_remain[target_user]['book_id'])\n",
    "if target_user in dict_unknown:\n",
    "    pprint(dict_unknown[target_user]['book_id'])\n",
    "\n",
    "test_dict = {}\n",
    "train_dict = {}\n",
    "for userMeta in dict_user:\n",
    "    ## 注意，这里是跳过了评论少于10个的\n",
    "#    if len(dict_user[userMeta]['book_id']) < 10:\n",
    "#        continue;\n",
    "    test_dict[userMeta] = {};\n",
    "    train_dict[userMeta] = {};\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_id,all_rating,test_size=0.33)\n",
    "    test_dict[userMeta]['book_id'] = x_test;\n",
    "    test_dict[userMeta]['rate'] = y_test;\n",
    "    train_dict[userMeta]['book_id'] = x_train;\n",
    "    train_dict[userMeta]['rate'] = y_train;\n",
    "\n",
    "#for userMeta in dict_remain:\n",
    "#    if userMeta not in train_dict:\n",
    "#        train_dict[userMeta] = {}\n",
    "#        train_dict[userMeta]['book_id'] = []\n",
    "#        train_dict[userMeta]['rate'] = []\n",
    "#    train_dict[userMeta]['book_id'].extend(dict_remain[userMeta]['book_id']);\n",
    "#    train_dict[userMeta]['rate'].extend(dict_remain[userMeta]['rate']);\n",
    "\n",
    "#for userMeta in dict_unknown:\n",
    "#    if userMeta not in train_dict:\n",
    "#        train_dict[userMeta] = {}\n",
    "#        train_dict[userMeta]['book_id'] = []\n",
    "#        train_dict[userMeta]['rate'] = []\n",
    "#    train_dict[userMeta]['book_id'].extend(dict_unknown[userMeta]['book_id']);\n",
    "#    train_dict[userMeta]['rate'].extend(dict_unknown[userMeta]['rate']);\n",
    "pprint(len(train_dict))\n",
    "pprint(len(test_dict)) #打印筛选后的用户数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1afe8b35c5e568e95bc17e5b5cdbfd1b\n",
      "{'17333426': 5, '20613635': 4}\n"
     ]
    }
   ],
   "source": [
    "print(conv_user[1])\n",
    "print(train_[conv_user[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE value is: 0.6927776219125726\n",
      "The RMSE value is: 0.9349987563510308\n"
     ]
    }
   ],
   "source": [
    "#进行预测和评估\n",
    "pred_res = pred_test(train_, test_, 10000);\n",
    "mae = cal_mae(test_, pred_res);\n",
    "rmse = cal_rmse(test_, pred_res);\n",
    "print(\"The MAE value is:\", mae)\n",
    "print(\"The RMSE value is:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6562182740254755\n",
      "0.8625402381412787\n"
     ]
    }
   ],
   "source": [
    "#进行改进版预测\n",
    "pred_res_im = pred_test_im(train_, test_, 10000);\n",
    "mae_im = cal_mae(test_, pred_res_im);\n",
    "rmse_im = cal_rmse(test_, pred_res_im);\n",
    "print(mae_im)\n",
    "print(rmse_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664604524863647\n",
      "0.8687005229252904\n"
     ]
    }
   ],
   "source": [
    "#对cos进行计算\n",
    "pred_res_cos = pred_test_cos(train_, test_, 1000);\n",
    "mae_cos = cal_mae(test_, pred_res_cos);\n",
    "rmse_cos = cal_rmse(test_, pred_res_cos);\n",
    "print(mae_cos)\n",
    "print(rmse_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对cos进行计算\n",
    "pred_res_cos = pred_test_cos(train_, test_, 10000);\n",
    "mae_cos = cal_mae(test_, pred_res_cos);\n",
    "rmse_cos = cal_rmse(test_, pred_res_cos);\n",
    "print(mae_cos)\n",
    "print(rmse_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_id': '46231',\n",
      " 'date_added': 'Tue Aug 25 19:04:35 -0700 2015',\n",
      " 'date_updated': 'Tue Aug 25 19:04:36 -0700 2015',\n",
      " 'isRead': False,\n",
      " 'rating': 0,\n",
      " 'read_at': '',\n",
      " 'review_id': '6aa2d9f629fc4531dff4bfd2eab3ab0a',\n",
      " 'started_at': '',\n",
      " 'user_id': '854d7eea57ee70acf835e2ba5262e3d9'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-fb5508f2fbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#得到根据book得到的信息的所有结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataBooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'goodreads_books_poetry.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#pprint(dataBooks[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eadcc68d3d02>\u001b[0m in \u001b[0;36mloadFile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mdatas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#得到根据book得到的信息的所有结果\n",
    "dataBooks = loadFile('goodreads_books_poetry.json')\n",
    "#pprint(dataBooks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'book_id': '1376',\n",
      " 'date_added': 'Wed May 09 09:33:18 -0700 2007',\n",
      " 'date_updated': 'Wed May 09 09:33:18 -0700 2007',\n",
      " 'isRead': True,\n",
      " 'rating': 4,\n",
      " 'read_at': '',\n",
      " 'review_id': '403a2391eca7dc8651e89de396e436e7',\n",
      " 'started_at': '',\n",
      " 'user_id': '8842281e1d1347389f2ab93d60773d4d'}\n"
     ]
    }
   ],
   "source": [
    "#得到根据user得到信息的所有结果\n",
    "dataUserMeta = loadFile('goodreads_interactions_poetry.json')\n",
    "pprint(dataUserMeta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#想法，进行评论，用什么进行排序呢？ 进行CB\n",
    "#pprint(dataUserMeta[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transToDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-be87a4b3c38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdict_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdict_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataUserMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#pprint(dict_user['8842281e1d1347389f2ab93d60773d4d']) #将最基本的meta数据转化为dict-array数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transToDict' is not defined"
     ]
    }
   ],
   "source": [
    "dict_user = {}\n",
    "dict_user = transToDict(dataUserMeta);\n",
    "#pprint(dict_user['8842281e1d1347389f2ab93d60773d4d']) #将最基本的meta数据转化为dict-array数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282415\n"
     ]
    }
   ],
   "source": [
    "pprint(len(dict_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_remain = {}\n",
    "dict_remain = transFindRemain(dataUserMeta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}\n",
    "train_dict = {}\n",
    "for userMeta in dict_user:\n",
    "    ## 注意，这里是跳过了评论少于10个的\n",
    "#    if len(dict_user[userMeta]['book_id']) < 10:\n",
    "#        continue;\n",
    "    test_dict[userMeta] = {};\n",
    "    train_dict[userMeta] = {};\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_id,all_rating,test_size=0.33)\n",
    "    test_dict[userMeta]['book_id'] = x_test;\n",
    "    test_dict[userMeta]['rate'] = y_test;\n",
    "    train_dict[userMeta]['book_id'] = x_train;\n",
    "    train_dict[userMeta]['rate'] = y_train;\n",
    "\n",
    "for userMeta in dict_remain:\n",
    "    all_id = dict_user[userMeta]['book_id'];\n",
    "    all_rating = dict_user[userMeta]['rate'];\n",
    "    if userMeta not in train_dict:\n",
    "        train_dict[userMeta] = {}\n",
    "        train_dict[userMeta]['book_id'] = []\n",
    "        train_dict[userMeta]['rate'] = []\n",
    "    train_dict[userMeta]['book_id'].extend(dict_remain[userMeta]['book_id']);\n",
    "    train_dict[userMeta]['rate'].extend(dict_remain[userMeta]['rate']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377799\n",
      "377799\n"
     ]
    }
   ],
   "source": [
    "#pprint(train_dict['8842281e1d1347389f2ab93d60773d4d'])\n",
    "#pprint(test_dict['8842281e1d1347389f2ab93d60773d4d'])\n",
    "pprint(len(train_dict))\n",
    "pprint(len(test_dict)) #打印筛选后的用户数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377799\n",
      "36514\n"
     ]
    }
   ],
   "source": [
    "#此时已经对数据进行了筛选\n",
    "dict_user = {}\n",
    "book_index = {}\n",
    "book_count = 0;\n",
    "user_index = {}\n",
    "user_count = 0;\n",
    "for username in test_dict:\n",
    "    if username not in user_index:\n",
    "        user_index[username] = user_count;\n",
    "        user_count += 1;\n",
    "    for book in test_dict[username]['book_id']:\n",
    "        if book not in book_index:\n",
    "            book_index[book] = book_count;\n",
    "            book_count += 1;\n",
    "\n",
    "for username in train_dict:\n",
    "    if username not in user_index:\n",
    "        user_index[username] = user_count;\n",
    "        user_count += 1;\n",
    "    for book in train_dict[username]['book_id']:\n",
    "        if book not in book_index:\n",
    "            book_index[book] = book_count;\n",
    "            book_count += 1;\n",
    "            \n",
    "pprint(len(user_index)) #用meta一个个存book_index和user_index 可能会用到\n",
    "pprint(len(book_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377799\n"
     ]
    }
   ],
   "source": [
    "#完全转化为dict-dict 第一个key是user的名字，第二个key是book的名字\n",
    "train_ = trans_array_to_dict(train_dict)\n",
    "test_ = trans_array_to_dict(test_dict)\n",
    "#userset = get_set([],train_dict);\n",
    "print(len(train_))\n",
    "#print(train_['8842281e1d1347389f2ab93d60773d4d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_avg = cal_avg(train_)\n",
    "#test_avg = cal_avg(test_) \n",
    "#测试cal_avg函数计算平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行预测\n",
    "pred_res = pred_test(train_, test_, 1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE value is: 0.5368075849751278\n",
      "The RMSE value is: 1.061675099643044\n"
     ]
    }
   ],
   "source": [
    "#进行评估\n",
    "pred_res = pred_test(train_, test_, 1000);\n",
    "mae = cal_mae(test_, pred_res);\n",
    "rmse = cal_rmse(test_, pred_res);\n",
    "print(\"The MAE value is:\", mae)\n",
    "print(\"The RMSE value is:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin: {'1376': 4}\n",
      "Predict: {'1376': 4.3165343528175155}\n",
      "Origin: {'30119': 3}\n",
      "Predict: {}\n",
      "Origin: {'30119': 4}\n",
      "Predict: {'30119': 4.0}\n",
      "Origin: {'30119': 5, '1420': 5}\n",
      "Predict: {'30119': 5, '1420': 5}\n",
      "Origin: {'2547': 4}\n",
      "Predict: {}\n",
      "Origin: {'1381': 5, '18743': 5}\n",
      "Predict: {'1381': 5.0, '18743': 5.0}\n",
      "Origin: {'30119': 5}\n",
      "Predict: {}\n",
      "Origin: {'1381': 4}\n",
      "Predict: {'1381': 4.0}\n",
      "Origin: {'35606560': 4}\n",
      "Predict: {}\n",
      "Origin: {'2696': 4}\n",
      "Predict: {}\n",
      "Origin: {'23513349': 5}\n",
      "Predict: {}\n",
      "Origin: {'15812153': 4}\n",
      "Predict: {}\n",
      "Origin: {'42038': 5, '53022': 5}\n",
      "Predict: {'42038': 5.0, '53022': 5.0}\n",
      "Origin: {'402128': 5}\n",
      "Predict: {'402128': 4.0}\n",
      "Origin: {'908708': 4}\n",
      "Predict: {'908708': 3.97093354507458}\n",
      "Origin: {'19351': 3}\n",
      "Predict: {'19351': 4.0}\n",
      "Origin: {'1420': 5}\n",
      "Predict: {'1420': 5.0}\n",
      "Origin: {'253264': 5}\n",
      "Predict: {}\n",
      "Origin: {'23534': 5}\n",
      "Predict: {'23534': 5.0}\n",
      "Origin: {'30119': 5}\n",
      "Predict: {'30119': 5.0}\n",
      "Origin: {'1432': 5}\n",
      "Predict: {}\n"
     ]
    }
   ],
   "source": [
    "#打印前20个预测结果\n",
    "count = 0;\n",
    "for user in pred_res:\n",
    "    print(\"Origin:\", test_[user]);\n",
    "    print(\"Predict:\",pred_res[user]);\n",
    "    count += 1;\n",
    "    if count > 20:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8230888470445363\n",
      "1.1405403810129706\n"
     ]
    }
   ],
   "source": [
    "#进行改进版预测\n",
    "pred_res_im = pred_test_im(train_, test_, 1000);\n",
    "mae_im = cal_mae(test_, pred_res_im);\n",
    "rmse_im = cal_rmse(test_, pred_res_im);\n",
    "print(mae_im)\n",
    "print(rmse_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214173117507653\n",
      "1.137028247304502\n"
     ]
    }
   ],
   "source": [
    "#对改进版进行预测\n",
    "pred_res_cos = pred_test_cos(train_, test_, 1000);\n",
    "mae_cos = cal_mae(test_, pred_res_cos);\n",
    "rmse_cos = cal_rmse(test_, pred_res_cos);\n",
    "print(mae_cos)\n",
    "print(rmse_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[19, 22],\n",
      "       [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,5).reshape(2,2)\n",
    "b = np.arange(5,9).reshape(2,2)\n",
    "c = np.dot(a, b)\n",
    "pprint(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19. 22.]\n",
      " [43. 50.]]\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((len(a), len(b[0])))\n",
    "for i in range(len(a)):\n",
    "    z[i, :] = np.dot(a[i, :], b)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2547175167898095\n",
      "1.6589688704114107\n",
      "4872\n",
      "1.2547175167898095\n",
      "2.752177712994112\n"
     ]
    }
   ],
   "source": [
    "rm_all = 0;\n",
    "mae_all = 0;\n",
    "count = 0;\n",
    "for user in pred_res_im:\n",
    "    for book in pred_res_im[user]:\n",
    "        diff = np.abs(pred_res_im[user][book] - test_[user][book]);\n",
    "        mae_all += diff\n",
    "        rm_all += (diff * diff);\n",
    "        count += 1;\n",
    "mae = mae_all / count;\n",
    "rm = (rm_all / count) ** 0.5\n",
    "print(mae);\n",
    "print(rm);\n",
    "print(count)\n",
    "print(mae_all/count)\n",
    "print(rm_all/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33926\n",
      "27978\n"
     ]
    }
   ],
   "source": [
    "pprint(len(book_index))\n",
    "pprint(len(user_index))\n",
    "#利用user_index和book_index构建二维矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_user = convert_dict(user_index)\n",
    "conv_book = convert_dict(book_index)\n",
    "#转化为通过数字找user和book的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f88032f4ad97b46654fe59ce3387cf5d\n"
     ]
    }
   ],
   "source": [
    "print(conv_user[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = 0.01 #Regularisation weight\n",
    "k = 20\n",
    "m = len(user_index) #user的矩阵长度\n",
    "#m = 1000\n",
    "#m = len(user_index)\n",
    "n = len(book_index) #book的矩阵长度\n",
    "n_epochs = 50\n",
    "gamma = 0.001 #learning rate\n",
    "P = 1 * np.random.rand(k, m)\n",
    "Q = 1 * np.random.rand(k, n)\n",
    "\n",
    "#len_user = 10000\n",
    "#R = np.zeros((len(user_index), len(book_index)));\n",
    "#I = np.zeros((len(user_index), len(book_index)));\n",
    "R = np.zeros((m, len(book_index)));\n",
    "I = np.zeros((m, len(book_index)));\n",
    "count = 0;\n",
    "for user_in in range(m):\n",
    "    user = conv_user[user_in] #得到user是哪个\n",
    "    if user not in train_:\n",
    "        continue;\n",
    "    for book in train_[user]:\n",
    "        R[user_index[user]][book_index[book]] = train_[user][book]\n",
    "        I[user_index[user]][book_index[book]] = 1\n",
    "    count += 1;\n",
    "\n",
    "count = 0;\n",
    "#T = np.zeros((len(user_index), len(book_index)));\n",
    "#I2 = np.zeros((len(user_index), len(book_index)));\n",
    "T = np.zeros((m, len(book_index)));\n",
    "I2 = np.zeros((m, len(book_index)));\n",
    "for user_in in range(m):\n",
    "    user = conv_user[user_in]\n",
    "    if user not in test_:\n",
    "        continue;\n",
    "#    pprint(user);\n",
    "    for book in test_[user]:\n",
    "        T[user_index[user]][book_index[book]] = test_[user][book] #test set\n",
    "        I2[user_index[user]][book_index[book]] = 1\n",
    "#构建两个矩阵，R和T分别存储train和test的信息\n",
    "#矩阵I I2分别存储项对应的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27978\n"
     ]
    }
   ],
   "source": [
    "print(len(P[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "lmbda = 0.02\n",
    "n_epochs = 50\n",
    "gamma = 0.005 #learning rate\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "user, book = R.nonzero()\n",
    "for epoch in range(n_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch)\n",
    "    for u, i in zip(user, book):\n",
    "        e = R[u, i] - prediction(P[:,u], Q[:, i])\n",
    "        P[:, u] += gamma * (e * Q[:, i] - lmbda * P[:, u])\n",
    "        Q[:, i] += gamma * (e * P[:, u] - lmbda * Q[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0.46562236, 0.67916067, 0.44680695, 0.18390048, 0.64692949,\n",
      "       0.01755266, 0.09910645, 0.52350605, 0.04623374, 0.6169816 ,\n",
      "       0.66349279, 0.61015071, 0.40297021, 0.78651147, 0.72557995,\n",
      "       0.41856451, 0.36838965, 0.45838551, 0.70199411, 0.52532535])\n"
     ]
    }
   ],
   "source": [
    "pprint(P[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'done'\n"
     ]
    }
   ],
   "source": [
    "PredM = predictions(P, Q, T)\n",
    "pprint(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167272.55971899832\n"
     ]
    }
   ],
   "source": [
    "pprint(sum(sum(PredM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'26b5bed05bcabbabdaec4ee08fc43244'\n",
      "{'12914': 4, '1371': 5, '1381': 5, '1519': 4, '1715': 4, '2696': 4, '764332': 4}\n",
      "1\n",
      "13969\n",
      "[('2696138', 4.894076124127441),\n",
      " ('574266', 4.894072835925565),\n",
      " ('30366501', 4.894001643840528),\n",
      " ('130229', 4.893988139079161),\n",
      " ('421012', 4.893971158023882),\n",
      " ('249105', 4.893943060730648),\n",
      " ('6033224', 4.8939172280449945),\n",
      " ('7042263', 4.893906349574056),\n",
      " ('6786717', 4.893885544049061),\n",
      " ('732354', 4.893858291337981),\n",
      " ('1406602', 4.893740752176383),\n",
      " ('569326', 4.893674691800695),\n",
      " ('567698', 4.893616644138188),\n",
      " ('1389984', 4.893428089150204),\n",
      " ('13368928', 4.8934232639710675),\n",
      " ('16029464', 4.89322380227537),\n",
      " ('1408793', 4.893115354372867),\n",
      " ('1320624', 4.893081648715032),\n",
      " ('11826882', 4.892985310504306),\n",
      " ('10757352', 4.892974568363418),\n",
      " ('1136122', 4.892965017671003),\n",
      " ('17789295', 4.892944561298616),\n",
      " ('217967', 4.8928639730324734),\n",
      " ('1654579', 4.892848076079172),\n",
      " ('23358157', 4.892752451059529),\n",
      " ('12482896', 4.892731881592242),\n",
      " ('1689292', 4.892623924084111),\n",
      " ('463688', 4.8926112442339775),\n",
      " ('1107026', 4.89255166968039),\n",
      " ('342391', 4.8925412652258276),\n",
      " ('1727572', 4.892529336420427),\n",
      " ('10310790', 4.89249473040496),\n",
      " ('794940', 4.892485896622762),\n",
      " ('21567698', 4.892253196101085),\n",
      " ('35715114', 4.892177080033942),\n",
      " ('1738831', 4.892081681083262),\n",
      " ('902906', 4.892024182987542),\n",
      " ('896312', 4.89199462126491),\n",
      " ('1221787', 4.891960968282882),\n",
      " ('18679203', 4.891894925696361),\n",
      " ('14910367', 4.891847627452767),\n",
      " ('10253687', 4.891811693762541),\n",
      " ('11735724', 4.8914262150323715),\n",
      " ('17402650', 4.891416500431596),\n",
      " ('16000375', 4.891383867669489),\n",
      " ('135922', 4.891374531984345),\n",
      " ('7872925', 4.891292275478844),\n",
      " ('32194768', 4.891279214746934),\n",
      " ('39690', 4.891222385504307),\n",
      " ('953562', 4.891216656608748)]\n"
     ]
    }
   ],
   "source": [
    "target_index = user_index['26b5bed05bcabbabdaec4ee08fc43244']\n",
    "pprint(conv_user[0])\n",
    "pprint(train_['26b5bed05bcabbabdaec4ee08fc43244'])\n",
    "\n",
    "dict_s = {}\n",
    "for i in range(len(PredM[0])):\n",
    "    if PredM[0][i] != 0:\n",
    "        book = conv_book[i];\n",
    "        dict_s[book] = PredM[0][i]\n",
    "\n",
    "pprint(len(res))\n",
    "result = dict_s\n",
    "sorted_x=sorted(result.items(), key = operator.itemgetter(1))\n",
    "#pprint(sorted_x[len(sorted_x) - 1])\n",
    "start = len(sorted_x) - 20000;\n",
    "end = len(sorted_x) - 19950;\n",
    "#pprint(sorted_x[end][0])\n",
    "result_id = []\n",
    "for i in range(end, start, -1):\n",
    "    if i == end:\n",
    "        print(i)\n",
    "    if i == start:\n",
    "        print(i)\n",
    "    result_id.append(sorted_x[i])\n",
    "\n",
    "pprint(result_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167272.55971899832\n"
     ]
    }
   ],
   "source": [
    "print(sum(PredM[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15389\n",
      "6988\n",
      "15389\n",
      "6988\n",
      "15389\n",
      "6988\n",
      "15389\n",
      "6988\n"
     ]
    }
   ],
   "source": [
    "pprint(len(R))\n",
    "pprint(len(R[0]))\n",
    "pprint(len(T))\n",
    "pprint(len(T[0]))\n",
    "pprint(len(I))\n",
    "pprint(len(I[0]))\n",
    "pprint(len(I2))\n",
    "pprint(len(I2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE by Matrix Factorization with Stochastic Gradient Descent is : 0.6990096911033689\n",
      "RMSE by Matrix Factorization with Stochastic Gradient Descent is : 0.9173291196783132\n"
     ]
    }
   ],
   "source": [
    "#Tr = T[0:10000, :]\n",
    "MAE = mae(I2, T, PredM)\n",
    "RMSE = rmse(I2, T, PredM)\n",
    "print(\"MAE by Matrix Factorization with Stochastic Gradient Descent is :\", MAE)\n",
    "print(\"RMSE by Matrix Factorization with Stochastic Gradient Descent is :\", RMSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13594.37411840311\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(P[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
